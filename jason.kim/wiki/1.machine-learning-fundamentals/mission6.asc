= Guided Project: Predicting Car Prices

Practice the machine learning workflow using k-nearest neighbors to predict car prices.

== 1. Introduction To The Data Set
* 이 가이드 프로젝트는 차량의 속성을 이용해 가격을 예측하는 실습이다.

[source,python]
----
import pandas as pd
import numpy as np
colNames = ['symboling', 'normalized_losses', 'make', 'fuel_type', 'aspiration', 'num_doors', 'body_style', 'drive_wheels', 'engine_location', 'wheel_base', 'length', 'width', 'height', 'curb_weight', 'engine_type', 'num_cylinders', 'engine_size', 'fuel_system', 'bore', 'stroke', 'compression_ratio', 'horsepower', 'peak_rpm', 'city_mpg', 'highway_mpg', 'price']
cars = pd.read_csv('imports-85.data', names = colNames)
----

== 2. Data Cleaning
* 모든 숫자열의 값을 정규화 한다.
* 누락된 값이 있는 경우 예측 모델링에 사용이 불가능하다.
* 누락된 값을 처리하는 방법은 아래와 같이 세가지 방법이 있다.
1. 비슷한 차량들의 값으로 대체한다.
2. 해당 열을 사용하지 않는다.(drop)
3. 해당 컬럼을 사용하지 않는다.(drop)

[source,python]
----
print(len(cars))
tempCars = cars.drop(['symboling', 'normalized_losses', 'make', 'fuel_type', 'aspiration', 'num_doors', 'body_style', 'drive_wheels', 'engine_location', 'engine_type', 'num_cylinders', 'fuel_system'], axis=1)
tempCars = tempCars.dropna(axis=0)
tempCars = tempCars.apply(pd.to_numeric, errors='coerce')
normalized = (tempCars - tempCars.mean()) / tempCars.std()
normalized['price'] = tempCars['price']
normalized = normalized[normalized.notnull().all(axis=1)]
print(len(normalized))
----

== 3. Univariate Model
* 하나의 변수를 이용한 모델 생성

[source,python]
----
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
%matplotlib notebook

def knn_train_test(column_name, df, k):
    train_df = df.iloc[:100]
    test_df = df.iloc[100:]

    knn = KNeighborsRegressor(n_neighbors=k, algorithm='brute')
    knn.fit(train_df[[column_name]], train_df['price'])
    predictions = knn.predict(test_df[[column_name]])
    mse = mean_squared_error(test_df['price'], predictions)
    rmse = mse ** (1/2)
    return rmse


for i in normalized.columns:
    if (i == 'price'):
        continue
    for j in range(1, 10):
        print(i, j, knn_train_test(i, normalized, j))

rmses = []
for j in range(1, 10):
    rmses.append(knn_train_test('horsepower', normalized, j))


plt.scatter(x = range(1, 10), y = rmses)
plt.show()
----

== 4. Multivariate Model
* 여러개의 변수를 이용한 모델 생성

[source,python]
----
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
%matplotlib notebook

def knn_train_test(column_names, df, k):
    train_df = df.iloc[:100]
    test_df = df.iloc[100:]

    knn = KNeighborsRegressor(n_neighbors=k, algorithm='brute')
    knn.fit(train_df[column_names], train_df['price'])
    predictions = knn.predict(test_df[column_names])
    mse = mean_squared_error(test_df['price'], predictions)
    rmse = mse ** (1/2)
    return rmse

def sub_lists(my_list):
    subs = [[]]
    for i in range(len(my_list)):
        n = i+1
        while n <= len(my_list):
            sub = my_list[i:n]
            subs.append(sub)
            n += 1

    return subs

def feature_combination(column_names, n):
    result = []
    for i in sub_lists(column_names):
        if (len(i) == n):
            result.append(i)
    return result

columns = list(normalized.columns.drop('price'))

for fs in range(2, 5):
    featuresArr = np.asarray(feature_combination(columns, fs))
    for f in featuresArr:
        print(f)
        for j in range(1, 10):
            print(f, j, knn_train_test(f, normalized, j))
----

== 5. Hyperparameter Tuning
* KNN에서의 최적의 하이퍼 파라미터(K값)를 찾는다.

[source,python]
----
top_features = [['engine_size', 'bore'], ['horsepower', 'peak_rpm', 'city_mpg', 'highway_mpg'], ['compression_ratio', 'horsepower', 'peak_rpm', 'city_mpg', 'highway_mpg']]

j = 0
r = range(1, 26)
for features in top_features:
    rmses = []
    for i in r:
        rmses.append(knn_train_test(features, normalized, i))
    figure = plt.figure(j)
    plt.scatter(x = r, y = rmses)
    plt.show()
    j += 1
----
