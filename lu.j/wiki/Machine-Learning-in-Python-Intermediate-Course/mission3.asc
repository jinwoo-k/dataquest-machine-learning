= Multiclass classification

== 1. Introduction to the data
* 우리가 작업하게 될 데이터 셋에는 자동차 정보가 들어있음
* 이전의 분류데이터 셋과 달리 선택할 수 있는 세가지 범주를 가지므로 작업이 약간 더 어렵다.
* 아래는 데이터의 샘플이다.

[source,python]
----
18.0   8   307.0      130.0      3504.      12.0   70  1    "chevrolet chevelle malibu"
15.0   8   350.0      165.0      3693.      11.5   70  1    "buick skylark 320"
18.0   8   318.0      150.0      3436.      11.0   70  1    "plymouth satellite"
----

== 2. Dummy Variables
* 이전 분류 임무에서는 범주형 변수가 정수값(0, 1)을 사용하여 데이터 셋에 표현되었다.
* 이 데이터 셋에서는 범주형 변수 실린더, 연도, 원점 세개의 열이 있다.
* 범주형 값이 포함된 열에는 더미 변수를 사용해야한다.
* 카테고리가 2개 이상일때 카테고리를 나타내는 열을 만들어야함


== 3. Multiclass classification
* 이전 임무에서는 우리는 가능한 2개의 카테고리 or 클래스만 있는 바이너리 분류를 탐색했다.
* 3개 이상의 카테고리가 있을 때 멀티 클래스 분류 문제라고 부른다.
* 여러 방법 중 one-versus-all 에 대해 학습한다.
* one-versus-all
** 하나의 카테고리를 Positive 케이스로 선택하고 나머지를 False 케이스로 그룹화 하는 기법

== 4. Tranning a multiclass logistiuc regression model
* one-vs-all 접근법에서 n-class(여기서는 n=3) 분류 문제를 n개의 이진 분류 문제로 변환
** 북미 - 모든 차량이 Positive(1)로 간주, 아시아 및 유럽 - negative(0)
** 유럽에서 건설된 모든 차량이 Positive(1), 북미 및 아시아는 negative(0)으로 간주
** 아시아에서 건설된 모든 자동차 - Positive(1), 북미 및 유럽은 negative(0)
* 이 모델은 각각 0과 1 사이의 확률을 반환하는 바이너리 분류이다.

== 5. Testing the models
* 이제 각 카테고리에 대한 모델을 통해 테스트 데이터 셋을 실행하고 모델을 평가한다.

== 6. Choose the origin
* 확률이 가장 높은 값을 생산지로 추정한다.


== 예제

=== 1.

[source,python]
----
import pandas as pd
cars = pd.read_csv("auto.csv")
print(cars.head())
unique_regions = cars["origin"].unique()
print(unique_regions)
----

=== 2.

[source,python]
----
dummy_cylinders = pd.get_dummies(cars["cylinders"], prefix="cyl")
cars = pd.concat([cars, dummy_cylinders], axis=1)
dummy_years = pd.get_dummies(cars["year"], prefix="year")
cars = pd.concat([cars, dummy_years], axis=1)
cars = cars.drop("year", axis=1)
cars = cars.drop("cylinders", axis=1)
print(cars.head())
----

== 3.

[source,python]
----
shuffled_rows = np.random.permutation(cars.index)
shuffled_cars = cars.iloc[shuffled_rows]
highest_train_row = int(cars.shape[0] * .70)
train = shuffled_cars.iloc[0:highest_train_row]
test = shuffled_cars.iloc[highest_train_row:]
----

== 4.

[source,python]
----
from sklearn.linear_model import LogisticRegression

unique_origins = cars["origin"].unique()
unique_origins.sort()

models = {}
features = [c for c in train.columns if c.startswith("cyl") or c.startswith("year")]

for origin in unique_origins:
    model = LogisticRegression()

    X_train = train[features]
    y_train = train["origin"] == origin

    model.fit(X_train, y_train)
    models[origin] = model
----

=== 5.

[source,python]
----
testing_probs = pd.DataFrame(columns=unique_origins)
testing_probs = pd.DataFrame(columns=unique_origins)

for origin in unique_origins:
    # Select testing features.
    X_test = test[features]
    # Compute probability of observation being in the origin.
    testing_probs[origin] = models[origin].predict_proba(X_test)[:,1]
----

=== 6.

[source,python]
----
predicted_origins = testing_probs.idxmax(axis=1)
print(predicted_origins)
----
