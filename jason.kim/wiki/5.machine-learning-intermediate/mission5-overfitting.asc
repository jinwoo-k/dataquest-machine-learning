= Overfitting
Learn how to detect overfitting and about the bias-variance tradeoff.

== 1. Introduction
* 이번장은 오버피팅과 이를 피하는 방법을 배운다.
* 자동차의 연료 효율성에 영향을 미치는 7 가지 수치적 피쳐가 포함 된 자동차 데이터 세트를 이용한다.

[source,python]
----
import pandas as pd
columns = ["mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model year", "origin", "car name"]
cars = pd.read_table("auto-mpg.data", delim_whitespace=True, names=columns)
filtered_cars = cars[cars['horsepower'] != '?']
filtered_cars['horsepower'] = filtered_cars['horsepower'].astype('float')
----

== 2. Bias and Variance
* 오버피팅에 대한 이해의 핵심은 bias(편향) 와 variance(편차)에 대한 이해이다.
* bias
  ** 학습 알고리즘에 대한 잘못된 가정으로부터 초래되는 오류
  ** 예를 들어 자동차의 무게와 같은 단 하나의 특징은 자동차의 연료 효율과 관련된 것으로 가정할 때, 이는 높은 바이어스를 일으키는 단순하고 보편적인 회귀 모델로 피팅된다.
  ** 자동차의 연료 효율은 중량뿐만 아니라 다른 많은 요인들에 의해 영향을 받기 때문에 오류율이 높을 것이다.
* variance
  ** 모델의 예측된 값의 가변성 때문에 발생하는 오류
  ** 각 차량에 1000개의 기능을 갖춘 데이터 세트를 제공하고 모든 기능을 사용할 수 있는 복합적인 다 변수 회귀 모델(multivariate regression model)을 사용할 경우에는 낮은 바이어스 하지만 큰 편차를 갖는다.
* bais 와 variance trade off 관계이다.

== 3. Bias-variance tradeoff
* overfitting
  ** 모델이 훈련 세트에서 잘 수행되지만 새 데이터로 일반화되지 않는 경우
  ** 모델간의 상대적인 개념으로 이해해야 함.
  ** 모든 프로세스에는 관찰 할 수없는 고유 한 노이즈가 있으며, 이러한 노이즈까지 고려해 모델이 생성된 경우
* image:./images/m5_3_1.png[, 500]
* 모델의 바이아스 예측 방법
  ** 동일한 데이터 셋에 대해 다른 피쳐를 사용해 모델을 학습하고, 오류 점수를 계산
  ** 회귀 분석에서 평균 절대 오차, 평균 제곱 오차 또는 R 제곱을 사용
  ** 복잡한 다 변수 모델일 수록 편차의 증가
  ** 단 변수 모델은 언더핏, 복잡한 다 변수 모델은 오버핏 된다.
* 문제에 따라 신뢰할 수 있고 유용한 예측 모델을 구성하는 행복한 중간 단계(happy middle ground)가 있다.

[source,python]
----
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt


def train_and_test(filtered_cars, cols):
    lr = LinearRegression()
    lr.fit(filtered_cars[cols], filtered_cars["mpg"])

    prediction = lr.predict(filtered_cars[cols])
    mse = mean_squared_error(filtered_cars["mpg"], prediction)
    variance = np.var(predictions)
    return (mse, var)

(cyl_mse, cyl_var) = train_and_test(filtered_cars, ["cylinders"])
(weight_mse, weight_var) = train_and_test(filtered_cars, ["weight"])

----

== 4. Multivariate models
* MSE와 편차를 계산하는 함수를 이용해 더 복잡한 모델을 학습하고 이해한다.
[source,python]
----
# Our implementation for train_and_test, takes in a list of strings.
def train_and_test(cols):
    # Split into features & target.
    features = filtered_cars[cols]
    target = filtered_cars["mpg"]
    # Fit model.
    lr = LinearRegression()
    lr.fit(features, target)
    # Make predictions on training set.
    predictions = lr.predict(features)
    # Compute MSE and Variance.
    mse = mean_squared_error(filtered_cars["mpg"], predictions)
    variance = np.var(predictions)
    return(mse, variance)

one_mse, one_var = train_and_test(["cylinders"])
print(one_mse, one_var)

two_mse, two_var = train_and_test(["cylinders", "displacement"])
print(two_mse, two_var)

three_mse, three_var = train_and_test(["cylinders", "displacement", "horsepower"])
print(three_mse, three_var)

four_mse, four_var = train_and_test(["cylinders", "displacement", "horsepower", "weight"])
print(four_mse, four_var)

five_mse, five_var = train_and_test(["cylinders", "displacement", "horsepower", "weight", "acceleration"])
print(five_mse, five_var)

six_mse, six_var = train_and_test(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year"])
print(six_mse, six_var)

seven_mse, seven_var = train_and_test(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year", "origin"])
print(seven_mse, seven_var)
----

== 5. Cross validation
* 오버 피팅 여부 확인 방법
  ** in-sample error 와 out-of-sample error 비교
  ** 트레이닝셋의 오류와 테스트셋의 오류 비교
  ** corss-validation 비교
    *** 샘플 오류보다 cross validation 오류가 훨씬 높으면 문제가 있음.
    *** 트레이닝셋을 통한 모델이 외부에서는 일반화되지 않음
[source,python]
----
from sklearn.cross_validation import KFold
from sklearn.metrics import mean_squared_error
import numpy as np


def train_and_test(train, test, feature_cols, target_col):
    lr = LinearRegression()
    lr.fit(train[feature_cols], train[target_col])
    predictions = lr.predict(test[feature_cols])
    mse = mean_squared_error(test[target_col], predictions)
    variance = np.var(predictions)
    return(mse, variance)

def train_and_cross_val(cols):
    mse_list = []
    var_list = []

    kf = KFold(len(filtered_cars), n_folds=10, shuffle=True, random_state=3)
    for train_index, test_index in kf:
        train = filtered_cars.iloc[train_index]
        test = filtered_cars.iloc[test_index]
        mse, var = train_and_test(train, test, cols, "mpg")
        mse_list.append(mse)
        var_list.append(var)
    return (np.mean(mse_list), np.mean(var_list))

two_mse, two_var = train_and_cross_val(["cylinders", "displacement"])
print(two_mse, two_var)

three_mse, three_var = train_and_cross_val(["cylinders", "displacement", "horsepower"])
print(three_mse, three_var)

four_mse, four_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight"])
print(four_mse, four_var)

five_mse, five_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration"])
print(five_mse, five_var)

six_mse, six_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year"])
print(six_mse, six_var)

seven_mse, seven_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year", "origin"])
print(seven_mse, seven_var)
----

== 6. Plotting cross-validation error vs. cross-validation variance
* 이전 예제를 통해 피쳐가 늘어날수록 MSE는 줄며, 분산은 커지는걸 확인할 수 있었다.
[source,python]
----
import matplotlib.pyplot as plt

two_mse, two_var = train_and_cross_val(["cylinders", "displacement"])
three_mse, three_var = train_and_cross_val(["cylinders", "displacement", "horsepower"])
four_mse, four_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight"])
five_mse, five_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration"])
six_mse, six_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year"])
seven_mse, seven_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration","model year", "origin"])

plt.scatter(list(range(2,8)), [two_mse, three_mse, four_mse, five_mse, six_mse, seven_mse], color='r')

plt.scatter(list(range(2,8)), [two_var, three_var, four_var, five_var, six_var, seven_var], color='b')

plt.show()
----
* image:./images/m5_6_1.png[, 400]

== 7. Conclusion
* 고차원 다 변수 모델은 하위 다 변수 모델에 비해 오버핏 되지만, 샘플 내 오차 및 샘플 외 오차에서 많은 차이를 보이지 않았다.
* 가장 좋은 모델은 가장 간단한 모델보다 약 50 % 더 정확하다.
* 반면에 모델의 복잡성이 증가함에 따라 전체 분산은 약 25 % 증가했습니다.
* 아직 발견하지 못한 새로운 데이터에 적용해봄으로써 모델의 검증을 이어나아가야 한다.
