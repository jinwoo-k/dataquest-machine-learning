= Overfitting
== 1. Introduction
  * 이  미션에서 우리는  오버피팅을 식별하는 방법과 이를 피하기 위해 할 수 있는 일을 모색 할 것임
  * 오버피팅을 탐색하기 위해 자동차의 연료 효율성에 영향을 줄 수있는 7 가지 속성이 포함 된 데이터 세트를 사용.
     ** cylinders - 엔진의 실린더 수.
     ** displacement - 엔진의 변위.
     ** horsepower  - 엔진의 마력.
     ** weight - 자동차의 무게.
     ** acceleration - 자동차의 가속.
     ** model year - 자동차 모델이 출시 된 연도 (예 : 70은 1970에 해당).
     ** origin  - 자동차 제조 국가 (북미 경우 0, 유럽 인 경우 1, 아시아 인 경우 2)
   * mmpg는  우리의 target 열이며 다른 속성을 사용하여 예측하고자 하는 열.

== 2. Bias and Variance
   * 바이어스와 분산은 우리가 간접적으로 제어 할 수있는 모델에서 관찰 가능한 2 가지 오류 원인을 구성.
   * 바이어스는 학습 알고리즘에 대한 잘못된 가정을 초래하는 오류를 설명
     ** 예를 들어, 자동차의 무게와 같은 단 하나의 속성만이 자동차의 연료 효율과 관련된다고 가정하면 높은 바이어스를 초래할 수있는 단순하고 단일변량의 회귀 모델에 적합하게 됩.
     ** 자동차의 연비는 무게뿐 아니라 다른 많은 요소의 영향을 받기 때문에 오류율이 높다.
   * 분산은 모델의 예측 된 값의 다양성 때문에 발생하는 오류를 설명.
     **  각 자동차에 1000 개의 피쳐가있는 데이터 세트를 제공하고 매우 복잡한 다중 변수 회귀 모델을 훈련하기 위해 모든 속성을 사용하면 편차는 적지만 분산은 커진다.
   * 이상적으로 낮은 편향과 낮은 편차를 원하지만 실제로는 항상 트레이드 오프가 존재.

== 3. Bias-variance tradeoff
  * 모델이 훈련 세트에서 잘 수행되지만 새 데이터로 일반화되지 않는 경우 일반적으로 오버피팅이 어떻게 발생하는 가를 먼저 살펴 보았다.
  * 여기서 중요한 뉘앙스는 오버피팅을 상대적인 용어로 생각해야 한다는 것임.
  * 편향 분산 트레이드 오프를 이해하는 것은 오버피팅 이해에 중요함.
  * 모든 프로세스에는 관찰 할 수없는 고유 한 소음이 있습니다. 과잉 모델은 데이터 세트의 신호뿐만 아니라 잡음을 포착하는 경향이 있다.

image:./images/m5-1.PNG[]

 * 동일한 데이터 세트에서 서로 다른 속성을 사용하여 몇 가지 모델을 학습하고 오류 점수를 계산하여 모델의 편향을 근사 할 수 있다.
   ** 회귀 분석에서 평균 절대 오차, 평균 제곱 오차 또는 R 제곱을 사용할 수 있다.
 * 극단적으로 단순한 단변량 선형 회귀 모형은 과소적합(undeffit)하지만, 매우 복잡한 다변수 선형회귀모형은 과적합(overfit) 할 것임.
 * 문제에 따라 신뢰할 수 있고 유용한 예측 모델을 구성하는 데 도움이 되는 중간이 있다.
 * 먼저 모델을 훈련하고 편향 및 분산 값을 계산하고 이를 사용하여 단순하고 단 변량 인 모델을 훈련시키는 데 사용할 수있는 함수를 만들어 보자.

```
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt
def train_and_test(cols):
    # Split into features & target.
    features = filtered_cars[cols]
    target = filtered_cars["mpg"]
    # Fit model.
    lr = LinearRegression()
    lr.fit(features, target)
    # Make predictions on training set.
    predictions = lr.predict(features)
    # Compute MSE and Variance.
    mse = mean_squared_error(filtered_cars["mpg"], predictions)
    variance = np.var(predictions)
    return(mse, variance)

cyl_mse, cyl_var = train_and_test(["cylinders"])
weight_mse, weight_var = train_and_test(["weight"])
```

== 4. Multivariate models

```
# Our implementation for train_and_test, takes in a list of strings.
def train_and_test(cols):
    # Split into features & target.
    features = filtered_cars[cols]
    target = filtered_cars["mpg"]
    # Fit model.
    lr = LinearRegression()
    lr.fit(features, target)
    # Make predictions on training set.
    predictions = lr.predict(features)
    # Compute MSE and Variance.
    mse = mean_squared_error(filtered_cars["mpg"], predictions)
    variance = np.var(predictions)
    return(mse, variance)

one_mse, one_var = train_and_test(["cylinders"])
two_mse, two_var = train_and_test(["cylinders", "displacement"])
three_mse, three_var = train_and_test(["cylinders", "displacement", "horsepower"])
four_mse, four_var = train_and_test(["cylinders", "displacement", "horsepower", "weight"])
five_mse, five_var = train_and_test(["cylinders", "displacement", "horsepower", "weight", "acceleration"])
six_mse, six_var = train_and_test(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year"])
seven_mse, seven_var = train_and_test(["cylinders", "displacement", "horsepower", "weight", "acceleration","model year", "origin"])

print(one_var,two_var,three_var,four_var,five_var,six_var,seven_var)

print(one_mse,two_mse,three_mse,four_mse,five_mse,six_mse,seven_mse)
```

* var : 36.7425588742 39.4806813867 40.5097836026 42.9988778705 43.0013423369 49.1725674609 49.9152574973
* mse : 24.0201795682 21.2820570556 20.2529548397 17.7638605718 17.7613961054 11.5901709814 10.847480945

== 5. Cross validation
   * 훈련된 다변수 회귀모델은 오류의 양을 줄이는 데 점진적으로 나아졌다. (mse)
   * 모델이 오버피팅인지 여부를 감지하는 좋은 방법은 train error 를 test error와 비교하는 것입니다.
   * 불행히도 별도의 테스트 데이터 집합이 없으므로 대신 교차 유효성 검사를 사용합니다.
   * 모델의 교차 유효성 검사 오류 (샘플 오류 이상)가 샘플 오류보다 훨씬 높으면 경고를 울리기 시작해야 함.
   * 이것은 overfitting에 대한 방어의 첫 번째 라인이며 훈련 된 모델이 교육 세트 외부에서 잘 일반화되지 않는다는 분명한 지표임.

```
from sklearn.cross_validation import KFold
from sklearn.metrics import mean_squared_error
import numpy as np
def train_and_cross_val(cols):
    features = filtered_cars[cols]
    target = filtered_cars["mpg"]

    variance_values = []
    mse_values = []

    # KFold instance.
    kf = KFold(n=len(filtered_cars), n_folds=10, shuffle=True, random_state=3)

    # Iterate through over each fold.
    for train_index, test_index in kf:
        # Training and test sets.
        X_train, X_test = features.iloc[train_index], features.iloc[test_index]
        y_train, y_test = target.iloc[train_index], target.iloc[test_index]

        # Fit the model and make predictions.
        lr = LinearRegression()
        lr.fit(X_train, y_train)
        predictions = lr.predict(X_test)

        # Calculate mse and variance values for this fold.
        mse = mean_squared_error(y_test, predictions)
        var = np.var(predictions)

        # Append to arrays to do calculate overall average mse and variance values.
        variance_values.append(var)
        mse_values.append(mse)

    # Compute average mse and variance values.
    avg_mse = np.mean(mse_values)
    avg_var = np.mean(variance_values)
    return(avg_mse, avg_var)

two_mse, two_var = train_and_cross_val(["cylinders", "displacement"])
three_mse, three_var = train_and_cross_val(["cylinders", "displacement", "horsepower"])
four_mse, four_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight"])
five_mse, five_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration"])
six_mse, six_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year"])
seven_mse, seven_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration","model year", "origin"])

print(one_var,two_var,three_var,four_var,five_var,six_var,seven_var)

print(one_mse,two_mse,three_mse,four_mse,five_mse,six_mse,seven_mse)
```

* var : 36.7425588742 38.9025253138 40.0912879566 42.5076436436 42.5987363001 48.9282469677 49.904313731
* mse : 24.0201795682 21.584370275 20.6556221939 18.1696832391 18.2830385172 12.0996854255 11.4181319718

== 6. Plotting cross-validation error vs. cross-validation variance
  * 교차 유효성 검사 중에 모델에 추가 된 속성이 많을수록 평균 제곱 오류가 낮아집니다.
  * 이것은 좋은 신호이며 모델이 훈련되지 않은 새로운 데이터로 잘 일반화되어 있음을 나타냅니다.
  * 그러나 평균 제곱 오류 값이 낮아짐에 따라 예측의 분산이 커졌습니다
  * 낮은 제곱오류값을 가진 모델은 모델의 복잡도가 높고 입력값의 작은 변동에 민감한 경향이 있다는 것을  예상 할 수 있다.

image:./images/m5-2.PNG[]

== 7. Conclusion
   * 차원 다변량 모델은 하위 다 변수 모델과 비교하여 오버피팅되지만, 샘플 내 오차 및 샘플 외 오차는 많은 차이를 보이지 않음.
     ** 가장 좋은 모델은 가장 간단한 모델보다 약 50 % 더 정확함
        *** (24.0201795682 - 11.4181319718) / 24.0201795682    = 0.5246441876347871
     ** 반면에 모델의 복잡성이 증가함에 따라 전체 분산은 약 35 % 증가
        ***   (49.904313731 - 36.7425588742) / 36.7425588742 = 0.35851337051
   
   
http://gentlej90.tistory.com/32[편향-분산 트레이드오프]

