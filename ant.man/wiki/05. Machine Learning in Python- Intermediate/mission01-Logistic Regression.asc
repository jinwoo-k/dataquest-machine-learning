== Logistic Regression
=== 1. Classification
* 선형회귀 복습: 종속 변수에 대해 목표값이 정렬되고 연속될때 잘 작동. (불연속 값이 있으면 적합치 않음)
* 분류 문제 (classification) : 각각 다른 카테고리 중 어디에 매핑되는지 확인
** binary classification : true/ false 갖음 (예: 이 학생이 기준에 통과 여부)

=== 2. Introduction to the data
* 예제 데이터: 입학 신청자들의 합격/불합격 분류
** gre: 일반 시험, 200~800 / gpa: 학점, 0.0~4.0 / admit: 1통과/0거절
*** gre + gpa 로 admit 예측

http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter[scatter]
```
admissions = pd.read_csv("admissions.csv")
plt.scatter(admissions['gpa'], admissions['admit'])
```

=== 3. Logistic regression
* 결과 그래프가 선형 관계가 아님, 0 or 1 이기 때문에 (범주형 데이터)
** 독립변수와 종속변수의 관계를 추정하는게 중요
* logistic regression : 선형 회귀 모델은 값으로 표출하지만, logistic 회귀는 가능한 값으로 표출
** binary 분류는 기준 확률(threshold probability)이 넘으면 1, 아니면 0 으로 표출
*** 기준 확률은 우리가 정함, 일단 logistic 회귀 동작이 어떻게 되는지부터 확인

=== 4. Logit function
* logit function: 출력은 확률값 (0 과 1 사이)
* image:./images/logic_func.png[]
** 모든 값을 양수로 변환: image:./images/e^t.png[]
** 모든 값을 0~1로 변환하는 정류화: image:./images/normalization.png[]

https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.exp.html[numpy.exp]
```
# Logit Function
def logit(x):
    # np.exp(x) raises x to the exponential power, ie e^x. e ~= 2.71828
    return np.exp(x)  / (1 + np.exp(x))

# Generate 50 real values, evenly spaced, between -6 and 6.
x = np.linspace(-6,6,50, dtype=float)

# Transform each number in t using the logit function.
y = logit(x)

# Plot the resulting data.
plt.plot(x, y)
plt.ylabel("Probability")
plt.show()
```

=== 5. Training a logistic regression model
* sciket-learn 로 모델 맞춰보기
** 하나의 feature로 예측: 단변랑 모델 (univariate model)

http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html[LogisticRegression]
```
from sklearn.linear_model import LinearRegression

linear_model = LinearRegression()
linear_model.fit(admissions[["gpa"]], admissions["admit"])
######### linear_model vs logistic_model ###
from sklearn.linear_model import LogisticRegression
logistic_model = LogisticRegression()
logistic_model.fit(admissions[["gpa"]], admissions["admit"])
```

=== 6. Plotting probabilities
* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba[predict_proba] 함수
* `probabilities = logistic_model.predict_proba(admissions[["gpa"]])`
** 0으로 될 확률: probabilities[:,0]
** 1로 될 확률: probabilities[:,1]

`plt.scatter(admissions["gpa"], probabilities[:,1])`

=== 7. Predict labels
* gpa 와 합격 확률은 선형 관계 -> logistic 회귀가 분류문제에 대한 선형회귀 버전
** http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict[predict]
