= Clustering Basics

== 1. Clustering overview
* 지금까지 지도학습 머신러닝의 두가지 유형 회귀와 분류에 대해 살펴보았다.
* 지도학습에서는 알려진 변수에서 알수없는 변수를 예측하는 알고리즘을 학습했다.
* 기계학습의 또 다른 주요 유형은 자율 학습이라고 한다.
* 비지도학습에서 우리는 예측하려고 하지 않고 데이터에서 패턴을 찾는다.
** 그 중 한가지 기술을 클러스터링이라고 한다.
* 데이터 집합을 탐색하려 할때 클러스터링을 사용하여 다양한 행과 열간의 연결을 이해한다.
** 예를 들어 NBA 선수를 통계를 기반으로 클러스터링 할 수 있다.

image::./images/6-1.PNG[NBA]

* 클러스터링 알고리즘은 유사한 행을 그룹화 한다.
* 데이터에는 하나 이상의 그룹이 있을수 있고 이 그룹은 클러스터를 형성한다.
* 클러스터링은 알려지지 않은 데이터를 탐색하는 핵심 방법이고 매우 일반적으로 사용되는 기계 학습 기술이다.
* 우리는 투표 방법에 따라 미국 상원 의원을 클러스터링 하는 작업을 할 예정이다.

== 2. The Dataset
* 상원은 제안된 입법안에 투표, 상원에 의해 통과된 법안을 얻는 것은 규정을 제정하기 위해 중요한 단계이다.
* 법안을 통과시키기 위해 다수결이 필요하다.
* roll call 투표로 알려진 투표의 결과는 공개되어 있다.
** https://en.wikipedia.org/wiki/Federal_government_of_the_United_States#Legislative_branch[rollcall참고]
* 상원 의원은 일반적으로 정당별 투표방식에 따라 투표한다.
* 114_congress.csv에는 114번째 상원에서 실시한 모든 롤 투표 결과가 포함되어 있다.
* 각 행은 한명의 상원의원을 나타내며 각 열은 투표를 나타낸다.
* 예를들어 0인 경우 상원의원이 법안에 반대표를 던졌음을 의미, 1은 찬성표를, 0.5는 기권을 의미한다.
** name - 상원의원의 이름
** party - 상원의원 파티 (D-민주당, R-공화당, I-독립국가)
** 00001, 00004 같은 번호가 지정된 열이 있는데 이 열은 단일 roll call 투표결과를 나타냄
* 우리는 이 클러스터링에서 상원의원이 속한 당의 관계에 따른 투표패턴보다 더 깊은 패턴을 알 수 있다.
** 예를 들어 일부 공화당원은 다른 정당보다 자유주의적이기도 하다.
** 투표데이터를 보면 그들의 당의 메인스트림에 속한 상원의원을 발견할 수 있다.
* 데이터 샘플

[source,python]
----
name,party,state,00001,00004,00005,00006,00007,00008,00009,00010,00020,00026,00032,00038,00039,00044,00047
Alexander,R,TN,0,1,1,1,1,0,0,1,1,1,0,0,0,0,0
Ayotte,R,NH,0,1,1,1,1,0,0,1,0,1,0,1,0,1,0
----

[source,python]
----
import pandas as pd
votes = pd.read_csv("114_congress.csv")
----

== 3. Exploring the data
* 데이터를 살펴보도록 한다.

image::./images/6-2.PNG[데이터]

[source,python]
----
print(votes["party"].value_counts())
print(votes.mean())
----

== 4. Distance between Senators
* 상원의원을 그룹화 하기 위해서는 서로 얼마나 가까운지를 파악할 방법이 필요하다.
* 우리는 두명의 상원 의원 투표가 얼마나 유사한지(같은 견해를 공유)를 발견할 수 있었고 이 거리를 수학적으로 발견할 수 있다.
* 유클리드 거리를 이용해 거리를 구한다.
* 두명의 상원의원 데이터를 가져와 투표 컬럼만 남긴다.

[source,python]
----
name,party,state,00001,00004,00005,00006,00007,00008,00009,00010,00020,00026,00032,00038,00039,00044,00047
Alexander,R,TN,0,1,1,1,1,0,0,1,1,1,0,0,0,0,0
Ayotte,R,NH,0,1,1,1,1,0,0,1,0,1,0,1,0,1,0
# 투표 내용만 남김
00001,00004,00005,00006,00007,00008,00009,00010,00020,00026,00032,00038,00039,00044,00047
0,1,1,1,1,0,0,1,1,1,0,0,0,0,0
0,1,1,1,1,0,0,1,0,1,0,1,0,1,0
----

* 유클리드 거리를 구한다.

image::./images/6-3.PNG[유클리드거리]

* 3가지를 제외하고 다른 견해는 같은 이 두 상원의원의 유클리드 거리는 1.73이다.

[source,python]
----
from sklearn.metrics.pairwise import euclidean_distances

print(euclidean_distances(votes.iloc[0,3:].reshape(1, -1), votes.iloc[1,3:].reshape(1, -1)))
distance = euclidean_distances(votes.iloc[0, 3:].reshape(1, -1),
                               votes.iloc[2, 3:].reshape(1, -1))
----

* 결과 : print - 1.73205081, distance - 3.31662479

== 5. Inital Clustering
* k-means 클러스터링이라는 알고리즘을 사용해 데이터를 클러스터로 분할하려고 한다.
* k-means 클러스터링은 유클리드 거리를 이용해 상원의원의 클러스터를 형성한다.
* 각 클러스터에 센터가 지정되고 각 상원의원과 센터간의 유클리드 거리를 계산하고 상원의원은 가장 가까운 클러스터에 배정된다.
* 우리는 상원의원이 당을 따라 모일 것이라고 예상한다.
* k-means 알고리즘은 클러스터 수를 미리 지정해야한다. 여기서 데이터는 정당(민주당, 공화당)에 따라 클러스터를 나눌 것이기 때문에 2로 선택할 것이다.
* 예측하지 않기 때문에 오버피팅의 위험이 없어서 전체 데이터로 모델을 학습시키게 된다.

[source,python]
----
# 학습
kmeans_model = KMeans(n_clusters=2, random_state=1)
# 결과값
array([[ 3.12141628,  1.3134775 ],
   [ 2.6146248 ,  2.05339992],
   [ 0.33960656,  3.41651746],
   [ 3.42004795,  0.24198446],
   [ 1.43833966,  2.96866004],
   [ 0.33960656,  3.41651746],
   [ 3.42004795,  0.24198446],
   [ 0.33960656,  3.41651746],
   [ 3.42004795,  0.24198446],
   [ 0.31287498,  3.30758755],
   ...
----

* 위 결과값의 첫번째 행은 첫번째 클러스터와 상원의원간의 유클리드 거리, 두번째는 두번째 클러스터와의 유클리드 거리를 뜻한다.

== 6. Initial clustering
* 예제

[source,python]
----
import pandas as pd
from sklearn.cluster import KMeans

kmeans_model = KMeans(n_clusters=2, random_state=1)
senator_distances = kmeans_model.fit_transform(votes.iloc[:, 3:])
----

== 7. Exploring the clusters
* Pandas의 crosstab() 함수는 두개의 벡터 또는 Pandas Series를 사용하고 첫번째 벡터의 각 고유값에 대해 두번째 벡터의 각 고유값이 몇번 발생하는지 계산해준다.
* 데이터 셋에서 crosstab()을 사용해 "party"(정당)와 비교하는 테이블을 만들수 있다.

[source,python]
----
labels = kmeans_model.labels_
print(pd.crosstab(labels, votes["party"]))
----

* 결과
[width="15%"]
|=======
|party|   D|  I|   R
|row_0| | |
|0|      41|  2|   0
|1|       3|  0|  54
|=======

== 8. Exploring Senators in the wrong cluster
* 우리 클러스터는 모두 정당을 따라 간 것으로 보인다.
* 공화당은 민주당원들과 투표하기 위해 당의원을 부수지 않았지만 민주당원 3명은 공화당원보다 공화당 후보들을 뽑았다.
* 파티열이 D고 labels 변수가 1인 선택행으로만 투표를 서브셋 하여 상원의원이 두번째 클러스터에 있음을 나타낼 수 있다.

[source,python]
----
democratic_outliers = votes[(labels == 1) & (votes["party"] == "D")]
print(democratic_outliers)
----

image::./images/6-4.PNG[결과값]

== 9. plotting out the clusters
* 클러스터를 탐색하는 좋은 방법 중 하나는 클러스터를 시각화 하는 것이다.
* 각 유클리드 거리를 x,y 좌표로 취급하여 상원의원의 위치를 보여주는 산점도로 만들수 있다.
* 산점도를 만들면서 소속에 따라 각 지점을 음영처리 할 수 있다.

[source,python]
----
plt.scatter(x=senator_distances[:,0], y=senator_distances[:,1], c=labels)
plt.show()
----

image::./images/6-5.PNG[결과]

== 10. Finding the most extreme
* 가장 급진적인 공화당원은 민주당과 멀리 떨어져 있을 것이다.
* 두 집단 사이에 있는 상원의원들은 온건한 성향이다.
* 상원의원의 유클리드 거리의 처음 몇 행을 보면 누가 더 극단적인지 알수 있다.

[source,python]
----
[
       [ 3.12141628,  1.3134775 ], # 약간 온건한 편, cluster 1로 부터는 멀고, cluster 2는 가까움.
       [ 2.6146248 ,  2.05339992], # 중도, cluster 1에서 멀고, cluster 2 멀다.
       [ 0.33960656,  3.41651746], # 약간 극단적, cluster 1 매우 가깝고, cluster 2는 매우 멈.
       [ 3.42004795,  0.24198446], # 아주 극단적, cluster 1 매우 멀고, cluster 2는 매우 가까움.
       ...
]
----

* 극단주의자를 찾기위해 수식을 만들것이다.
* 유클리드 거리를 모두 삼제곱하면 작은값과 높은값의 차이가 늘어난다.
** 예를 들면 [1,2,3] 제곱 => [1,4,9], 삼제곱 할 경우 [1,8,27]
* 극단주의자와 같은 거리를 가진 당원으로부터 더 멀리 있는 극단주의자들과 적당한 거리를 가진 중도 주의자들 사이에 좋은 분리를 할 수 있도록 거리를 정육면체로 만든다.
** [2.6, 2] 거리를 그대로 둔다면 3.4 + 0.24 = 3.64, 2.6 + 2 = 4.6 으로 중도가 극도로 보일 수 있다.
** 삼제곱을 한다면 3.4 ** 3 + 0.24 ** 3 = 39.3, 2.6 ** 3 + 2 ** 3 = 25.5 로 분리를 잘 할수 있게 된다.

[source,python]
----
[
       [ 3.12141628,  1.3134775 ], # 32.67
       [ 2.6146248 ,  2.05339992], # 26.5
       [ 0.33960656,  3.41651746], # 39.9
       [ 3.42004795,  0.24198446], # 40
       ...
]
----

[source,python]
----
extremism = (senator_distances ** 3).sum(axis=1)
votes["extremism"] = extremism
votes.sort_values("extremism", inplace=True, ascending=False)
print(votes.head(10))
----

image::./images/6-6.PNG[결과]

== 11. Next steps
* 클러스터링은 데이터를 탐색하고 패턴을 찾는 강력한 방법이다.
