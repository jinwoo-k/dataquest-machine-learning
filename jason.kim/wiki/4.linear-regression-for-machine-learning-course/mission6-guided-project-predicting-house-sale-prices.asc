= Guided Project: Predicting House Sale Prices

== 1. Introduction
* 이번 코스에서는 아래와 같은 사항을 배웠음
  ** 모델 기반 학습에 대한 이해
  ** 선형 회귀 모델의 작동 방식 이해
  ** 모델 피팅의 두가지 접근방식 학습
    ***
  ** cleaning, transforming, 피쳐 선택 등의 테크닉 학습
* 선형회귀를 통해 모델을 만드는 함수 파이프 라인
  ** image:./images/m6_1_1.png[, 200]

[source,python]
----
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

data = pd.read_csv("AmesHousing.txt", sep = '\t')
train = data.iloc[:1460]
test = data.iloc[1460:]

def transform_features(df):
    return df

def select_features(df):
    return df[['Gr Liv Area', 'SalePrice']]

def train_and_test():
    target_column = 'SalePrice'
    train_df = transform_features(train)
    test_df = transform_features(test)

    features = select_features(train_df).drop(target_column, 1)
    targets = select_features(train_df)[target_column]
    lr = LinearRegression()
    lr.fit(features, targets)

    train_prediction = lr.predict(features)
    train_mse = mean_squared_error(targets, train_prediction)
    train_rmse = np.sqrt(train_mse)

    test_features = select_features(test_df).drop(target_column, 1)
    test_targets = select_features(test_df)[target_column]

    test_prediction = lr.predict(test_features)
    test_mse = mean_squared_error(test_targets, test_prediction)
    test_rmse = np.sqrt(test_mse)

    return (train_rmse + test_rmse) / 2

print(train_and_test())
----

== 2. Feature Engineering
* 데이터 처리 순서
  ** 누락된 값이 많은 행을 제거
  ** 피쳐를 적절한 형식으로 변환(수치형 -> 범주형, scaling, filling missing values)
  ** 다른 피쳐의 조합으로 새로운 피쳐 생성

* 아래의 열은 즉지 제거
  ** PID 열
  ** 25% 이상 데이터가 누락된 열
  ** SalePrice 가 누락된 열

* 누락된 값을 채워야하는, 누락된 값이 0% 이상, 25% 이하인 열은 어떤게 있는지 확인
* 어떤 열을 범주형 데이터로 변환해야할지에 대한 고찰
  ** 고유값이 수백개인 경우 -> 더미 코드로 만들면 수백개의 열이 데이터프레임에 추가돼야 함
  ** 특정 고유값이 전체값의 95% 이상을 차지하는경우는 어떤게 있으며, 이런경우 포함해야하는지? (분산이 낮아 모델의 변동성이 없음)

* 숫자형으로 된 열 중 범주로 변환해야하는 열은?
* 피쳐의 조합을 통해 새롭게 만들 수 있는 피쳐가 있는가? (years_until_remod 와 같은..)
* 이 함수에 test 데이터셋을 넣어 사용한다.

[source,python]
----
def drop_too_many_missing_columns(df):
    null_count = df.isnull().sum()
    removes = null_count[null_count > len(df) * 0.25]
    return df.drop(removes.index.tolist(), axis=1)

def transform_features(df):
    new_df = drop_too_many_missing_columns(df)
    new_df = new_df.drop(['PID', 'Garage Yr Blt', 'Mo Sold', 'Yr Sold'], axis=1)
    new_df = new_df.dropna(axis=0, how='any')

    text_cols = new_df.select_dtypes(include=['object']).columns
    for col in text_cols:
        new_df[col] = new_df[col].astype('category')
        #print('-----' + col + '-----')
        #print(new_df[col].value_counts())

    # category 타입 House Style 에 대해서만 더미 코드 적용
    dummy = pd.get_dummies(new_df['House Style'])
    new_df = pd.concat([new_df, dummy], axis=1)
    del new_df['House Style']

    # years_until_remod 컬럼 생성, 'Year Built', 'Year Remod/Add' 컬럼 제거
    new_df['years_until_remod'] = new_df['Year Remod/Add'] - new_df['Year Built']
    new_df = new_df.drop(['Year Built', 'Year Remod/Add'], axis=1)
    return new_df

transform_features(test)
----

== 3. Feature Selection
* SalePrice 와 각 피쳐의 correlation 을 확인 한 후 사용할 피쳐 선택
* 히트맵 으로 각 피쳐간 상간관계 확인
* 범주형 컬럼에 대해 SalePrice 와의 correlation 은 어떻게 구할 수 있는지??


== 4. Train And Test
* k-fold validation 구현 (k 값을 10으로 평균 RMSE 구함)
