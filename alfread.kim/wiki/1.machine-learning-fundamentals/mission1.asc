
== 1. 문제 정의
 * 문제 :  "AirBnB와 같은 주거공간 임대시장을 예제로 하여 특정 임대 주거공간에 대한 최적의 임대료를 구하고자 한다" 
 * 문제를 해결하기 위한 전략 하나를 소개 
   ** 우리가 임대할 주거공간과 유사한 몇몇 목록을 찾는다. => 목록수집(data set)
   ** 우리의 것과 가장 유사한 몇개의 평균가격을 구한다. => 가장 유사한(neighbor,nearlest,distance) , 몇개의 (k) , average
   ** 계산된 평균 가격을 우리 것의 가격으로 설정한다.
 * 정의 : 예측을 위해 기존 데이터에서 패턴을 발견하는 프로세스를 기계학습이라 함.  => 데이터, 패턴 발견, 예측, 프로세스
 * 위에서 소개한 전략을 사용한 머신러닝 테크닉을 KNN(K-Nearest Neighbors) 이라 함.
 
== 2. 데이터 소개
 * 데이터에 대한 명세.

== 3. K-Nearest Neighbors
.KNN.
image::https://s3.amazonaws.com/dq-content/knn_infographic.png[KNN]
 * 필요한 두가지 상세한 내용
   ** 유사성 측정  => distance
   ** K값의 결정  => mae, mse, rmse로 비교
   
== 4. 유클리드 거리
.Euclidean Distance.
image::http://cfile28.uf.tistory.com/image/242971445236215901A900[Euclidean Distance]
  * 참고사항 (다양한 유사도 측정 방식)
    ** https://lyfat.wordpress.com/2012/05/22/euclidean-vs-chebyshev-vs-manhattan-distance/
    ** 그밖에 해밍거리 , 레벤슈타인 거리 , 상관계수 , 코사인 유사도 등 다양한 유사도 측정 방법이 존재

== 5. 모든 관측치의 거리 계산
.거리계산.
image::https://s3.amazonaws.com/dq-content/distance_between_rows_and_ours.png[거리계산]
  * 같이 생각해 볼 만 한 것 : KNN은 미리 학습하는 것이 가능할까?
  
== 6. 무작위화와 정렬
  * 어짜피 정렬하는데 왜 무작위화가 필요할까 ? 
     ** 동률이 많이 있는 경우 동률끼리의 순서는 원래 목록의 순서에 의존하기 때문.
  * 생각해 볼 만 한 것 : 나중에 훈련데이터와 테스트 데이터를 나눌 때에도 무작위화를 하면 통계적으로 좋은 샘플링을 할 수 있다.   
    
== 7. 평균 가격
  * 생각 해 볼 만 한 것 : 일반적으로 평균은 모든 대상의 가중치를 동일하게 두는 것인데 이것이 좋은 선택일까? => 가중평균, 가중치: 1/d
  
== 8. 예측 함수 (SKIP)
== 9. 다음 스텝으로... (SKIP)

---
== 참고 사항 (KNN 의 특징)
  * 장점 
     ** 단순하다
     ** 파라미터에 대한 가정이 거의 없다. (K:주위 개수)
     ** 학습데이터가 많을 때, 집단이 여러 예측변수들의 조합으로 결정지어질 때 좋은 성능을 보여준다. 
     ** 회귀와 분류 모두 가능
         *** 회귀 : 숫자값을 예측하는 것으로 위에서 학습한 대로 평균을 사용
         *** 분류 : 어느 그룹에 속하는지 정하기 위해 가장 유사한 K개 중에서 가장 높은 빈도의 그룹으로 분류
  * 단점 
     ** lazy learning : 모델을 학습시키는 과정이 빠져 있음. 결과적으로 느림. 
     
  
  
 
  
  
