== Evaluating Model Performance ==
=== step.1 Testing Quality Of Predictions
쉽게 퀄리티 테스트

. training / test set 두 개로 나눔
. training set 의 값을 통해 test set 의 값 예측.
. 예상값과 실제 값 비교

train/test validation : training set 으로 예측하고 테스트 셋 값을 예측

image:https://s3.amazonaws.com/dq-content/train_test_split.png[width="500px"]

=== step.2 Error Metrics
error metric : 얼마나 테스트 셋을 잘 예측했는지 퀄리티에 대한 매트릭스 클래스

오차의 척도를 무엇으로 할까?

MAE (mean absolute error) = ( | acutal(1) - pre(1) | + ... + | acutal(n) - pre(n) | ) / n

=== step.3 Mean Squared Error
MSE (mean squared error) = ( (acutal(1) - pre(1))^2 + ... + (acutal(n) - pre(n))^2 ) / n

=== step.4 Training Another Model
위에 나온 mse가 낮은지 높은지 모르기 때문에 다른걸 트래이닝 시켜 서로 값을 비교한다.(한개 모델로는 유용하지 않음)

=== step.5 Root Mean Squared Error
Root mean squared error (rmse) : 에러 매트릭스의 단위가 기본단위 (단위가 같아서 이해 더 쉬움)

rmse = mse ** (1/2)

=== step.6 Comparing MAE And RMSE
큰 차이점 : rmse 는 각 오류 값에 제곱이 됨 => 개별오차가 엄청나게 큰 결과값으로 변화됨

### 7: Next Steps
rmse 의 엄청난 오류 증가분을 줄이는 방법

k 값의 최적화를 통해 모델의 효율을 높인다

<비고>
오차(Error) : 예측값과 "참값" 의 차
편차(Deviation) : 자료값과 "평균" 의 차
앞으로 MAE, MSE, RMSE 를 배우게 되는데 MAD, MSD, RMSD도 있다. MSD는 분산, RMSD는 표준편차.
MAD는 평균절대편차 라고 하는데 표준편차가 산술평균에 대한 편차를 나타낸다면 MAD는 중앙값에 대한 편차를 뜻한다
