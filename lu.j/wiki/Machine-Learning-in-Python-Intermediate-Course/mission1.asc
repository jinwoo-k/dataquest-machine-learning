= Logistic Regression

== 1. Classification
* 이전 코스에서는 선형 회귀라는 기계학습 기술을 배웠다.
* 선형 회귀는 우리가 예측하려는 대상 열, 종속 변수가 정렬되어 있고 연속되어있을때 잘 작동한다.
* 대상열에 불연속 값이 포함되어 있으면 선형회귀가 적합하지 않음
* 분류문제에 대한 예측 모델을 작성하는 방법을 알아보자.
* 분류시에 목표컬럼은 행이 속할수 있는 다른 카테고리를 나타내는 유한 값의 셋을 가진다.
* 정수를 사용해서 서로 다른 범주를 표현하기 때문에 수학함수를 사용해서 독립 변수가 종속 변수에 어떻게 매핑되는지 설명할 수 있다.
* 바이너리 분류
** 0 - false
** 1 - true

* 이항 분류란 아래 그림처럼 분류할 수 있는 이상적인 직선 그래프를 찾는 것

image::./images/1-title.PNG[이항분류]

== 2. Introduction to the data
* 분류의 개념을 파악하기 위해 미국 대학의 대학원 과장에 지원자가 입학을 할것인지에 대한 여부를 예측해보자
* gre - 예비 대학원생을 위한 일반 시험에서의 지원자의 점수
** 점수는 200~800 사이
* gpa - 학점 평균
** 0.0 ~ 4.0 사이
* admit - 바이너리 값
** 이진 값, 0 또는 1, 여기서 1은 신청자가 프로그램에 참여했음을 의미, 0은 신청자가 거절당했음을 의미
* admit 열을 예측하기 위해서는 gpa, gre 열 모두 사용할 수 있지만 gpa열만 사용해서 간단히 유지하는데 초점을 맞춘다.

== 3. Logistic regression
* 앞선 그래프를 선형 회귀 모델로 정의해서 그래프를 그려보게 된다면 아래와 비슷하게 된다.

image::./images/1-linear.PNG[이항분류]

* 새로운 데이터가 오게되면 아래와 같이 변경된다.

image::./images/1-linear2.PNG[이항분류]

* 앞서 그래프에서 볼수 있듯이 gpa열과 admit 열이 명확한 선형 관계를 갖고있지 않음을 알수 있다.
* admit열에는 0 또는 1만 포함되며 이진값을 나타내는데 사용되며 숫자에 의미는 없음
* 숫자가 다른 옵션 또는 범주를 나타내는데 사용되면 범주형 값(categorical variable)이라고 함
* 분류(Classification)는 독립변수와 종속 변수인 범주형 변수 간의 관계를 추정하는데 초점을 둔다.
* 선형회귀
** 레이블로 출력
* 로지스틱 회귀(logistic regression)
** 확률값을 출력
** 이진 분류에서 확률 값이 특정 임계 확률보다 크면 해당 행의 레이블을 1로 지정하고 그렇지 않으면 0을 지정

== 4. Logit function
* 선형회귀 분석에서는 독립 변수와 종속 변수 간의 관계를 나타내기 위해 선형함수 y = mx + b를 사용함
* 로지스틱 회귀 분석에서는 분류에 적용되는 선형함수의 버전인 logit 함수를 사용한다.
* 출력이 실제 값일 수 있는 선형회귀와는 달리 로지스틱 회귀에서 출력은 확률값을 나타내기 때문에 0과 1사이의 값이어야한다.
* 모델은 음수 값을 출력할 수 없다.

image::./images/1-2.PNG[logit함수]

* logit 함수는 두부분으로 나뉜다.
** 모든값을 양수로 변환하는 지수 변환

image::./images/1-3.PNG[지수]

** 모든값을 0에서 1 사이의 범위로 변환하는 정규화 변환

image::./images/1-4.PNG[정규화]

* 지수변환과 정규화는 출력 값을 0에서 1사이로 제한한다.

image::./images/1-5.PNG[지수]

* 정규화 부분만으로는 음수값을 가질수 없다.

image::./images/1-6.PNG[정규화]

** 어떠한 일이 일어날 확률(1이 될 확률)을 일어나지 않을 확률 (1-t)로 나눈 것을 말한다.
* -무한대 ~ 무한대의 범위를 가지게 하기 위해 log를 씌움 log를 없애기 위해 지수를 취해줌

image::./images/1-func1.PNG[증명]
image::./images/1-func2.PNG[증명]
image::./images/1-func3.PNG[증명]

== 5. Training a logistic regression model
* gpa 하나만 가지고 훈련시킬 예정이기 때문에 단변량 모델이라고 한다.
* gpa가 0.0과 4.0사이에 포함되어 있으면 admit열에는 해당 신청자가 입학했는지 여부가 지정된다.

=== 6. Plotting probabilities
* 로지스틱 회귀 모형의 결과는 행을 True 또는 1로 표시해야할 확률이라고 했다.

[source,python]
----
probabilities = logistic_model.predict_proba(admissions[["gpa"]])
# Probability that the row belongs to label `0`.
probabilities[:,0]
# Probabililty that the row belongs to label `1`.
probabilities[:,1]
----

* 각 학생의 입학 확률을 반환한 후 결과를 시각화

image::./images/1-8.PNG[그래프]

== 7. Predict labels
* 그래프에서 gpa값과 합격될 확률 사이의 선형관계를 나타낸다.
* 로지스틱 회귀가 분류 문제에 대한 선형회귀의 버전이기 때문이다.
* 이제 트레이닝 데이터셋의 각 행에 대한 예측값을 반환해보자

== 8. Next Steps

참고 : http://bcho.tistory.com/1142[로지스틱회귀]

== 예제
=== 1.

[source,python]
----
import pandas as pd
import matplotlib.pyplot as plt
admissions = pd.read_csv("admissions.csv")
plt.scatter(admissions['gpa'], admissions['admit'])
plt.show()
----

image::./images/1-1.PNG[결과값]


=== 2.

[source,python]
----
import numpy as np

# Logit Function
def logit(x):
    # np.exp(x) raises x to the exponential power, ie e^x. e ~= 2.71828
    return np.exp(x)  / (1 + np.exp(x))

# Generate 50 real values, evenly spaced, between -6 and 6.
x = np.linspace(-6,6,50, dtype=float)

# Transform each number in t using the logit function.
y = logit(x)

# Plot the resulting data.
plt.plot(x, y)
plt.ylabel("Probability")
plt.show()
----
image::./images/1-7.PNG[결과값]


=== 3.

[source,python]
----
from sklearn.linear_model import LinearRegression
linear_model = LinearRegression()
linear_model.fit(admissions[["gpa"]], admissions["admit"])
from sklearn.linear_model import LogisticRegression
logistic_model = LogisticRegression()
logistic_model.fit(admissions[["gpa"]], admissions["admit"])
----

=== 7.

[source,python]
----
logistic_model = LogisticRegression()
logistic_model.fit(admissions[["gpa"]], admissions["admit"])
fitted_labels = logistic_model.predict(admissions[["gpa"]])
plt.scatter(admissions["gpa"], fitted_labels)
----

image::./images/1-9.PNG[결과값]
