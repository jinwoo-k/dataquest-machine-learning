= Hyperparameter Optimization

== 1. 요점 되풀이
* 지난 미션에서 속성을 선택해서 모델의 정확도를 향상시키는 방법을 살펴봄
** 일반적으로 더 많은 속성을 추가하여 모델의 오류를 낮출 수 있음
** 사용 가능한 모든 속성을 써도 정확도가 향상되지는 않음
** 일부 속성은 유사성 순위와 관련이 없는 것으로 보임
** 관련된 속성을 선택하는 것이 정확성을 향상시킬수 있음
* 이 미션에서는 K값이 증가할때의 영향에 초점을 맞춤

== 2. Hyperparameter 최적화
* K값 변경은 속성 변경과 달리 예측할 때 사용되는 데이터에 영향 없이 모델의 동작에 영향을 준다.

* HyperParameter란 ?
** 사용되는 데이터와 관련 없이 모델의 동작 및 성능에 영향을 미치는 값
* HyperParameter 최적화란 ?
** 최적의 HyperParameter를 찾는 프로세스
* 일반적인 HyperParameter 최적화 기법 (그리드 검색)
** 가능한 HyperParameter 값의 서브 셋 선택
** 각 HyperParameter 값을 사용하여 모델 학습
** 각 모델의 성능평가
** 가장 낮은 오류값의 HyperParameter 선택

* 그리드 검색은 기본적으로 다른 K값에서 모델 성능을 평가하고 가장 낮은 오류 값이 결과인 K를 선택한다.
* 대규모 데이터로 작업할때는 그리드 검색이 느림

* 예제에서는 K값을 1 ~ 5로 변화시키며 모델의 성능을 비교함
* 가장 정확도가 좋았던 속성값을 이용함

|===
| k	| MSE
| 1	| 26364.928327645051
| 2	| 15100.522468714449
| 3	| 14579.597901655923
| 4	| 16212.300767918088
| 5	| 14090.011649601822
|===

== 3. 그리드 검색 확장
* 그리드 검색을 K값이 20일때까지 확장
* 더 낮은 MSE가 나올것 같으면 K값을 증가시켜도 됨

== 4. HyperParameter 값 시각화
* 이제까지 시도한 K값 중에 K = 6일때 가장 MSE가 작았기 때문에 최적의 값으로 볼수 있다.
* K를 처음으로 올리면 오류율은 특정 시점까지 감소하지만 다시 반동하여 증가한다.

image::../../lu.j/wiki/machine-learning-fundamentals/images/4-5.PNG[result]

== 5. 다양한 속성들과 HyperParameter
* K값을 변화시키면 MSE 값이 감소
* K를 5로 고정한 뒤 가능한 모든 feature를 선택한 모델로 그리드 검색 프로세스 반복

image::../../lu.j/wiki/machine-learning-fundamentals/images/4-6.PNG[result]

== 6. 워크플로우 연습
* 가장 좋은 모델을 찾는 워크플로우는 아래와 같다.
** 대상 열을 예측하는데 사용할 관련 속성 선택
** 그리드 검색을 사용하여 선택한 속성에 대한 최적의 HyperParameter 값을 찾는다.
** 모델의 정확성을 평가하고 프로세스를 반복한다.
* 테스트 결과
** two_features = ['accommodates', 'bathrooms']
** three_features = ['accommodates', 'bathrooms', 'bedrooms']
** all_features (except price)
** two_hyp_mse = {5: 14790.314266211606}
** three_hyp_mse = {7: 13518.769009310208}
** all_hyp_mse = {11: 14711.46334583815}

== 7. Next Steps
* 수용인원과 욕실수를 속성선택한 경우 K=5 일 때 MSE = 14790.314266211606
* 수용인원,욕실수 와 침대방수를 속성선택한 경우 K=7 일 때 MSE = 13518.769009310208
* 속성선택[수용인원,욕실수 와 침대방수], K=7 인 경우가 전체속성을 선택한 경우보다 더 좋음
