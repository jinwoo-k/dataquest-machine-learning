= Cross Validation

== 1. 소개
* 이전에 머신러닝 모델의 정확성을 검증하기 위한 train/test 유효성 검사에 대해 배웠다.
* holdout validation 기술에 중점을 둔다.
** 풀 데이터 셋을 두가지 파티션으로 나눔
*** train
*** test
** train 셋으로 모델을 훈련시킨다
** 학습된 모델을 사용해서 테스트 셋의 레이블을 예측
** 모델의 효과를 이해하기 위해 에러 매트릭을 계산
** 훈련셋과 테스트셋을 바꿔서 반복
** 에러 평균을 구함

* holdout validation 에서는 보통 train/test 비율을 75/25 대신 50/50을 이용한다.


== 2. Holdout Validation
* 첫번째 데이터셋은 K-Nearest neightbors 모델로 학습
* 두번째 데이터셋은 테스트
* 두번째 데이터셋을 K-Nearest neightbors 모델로 학습
* 첫번째 데이터셋은 테스트


== 3. K-Fold Cross Validation
* Holdout Validation은 실제로 K-Fold Cross Validation의 특정 예이다.
* Holdout Validation은 모델이 데이터의 특정 하위 셋으로 반복적으로 편향되지 않기에 train/test 유효성 검사보다 낫지만 훈련된 두 모델 모두 데이터의 절반만 사용한다.
* K-Fold Cross Validation은 훈련 중 데이터의 더 많은 부분을 활용하면서 train/test 유효성 검사의 문제를 피하기 위해 데이터의 다른 하위 집합을 계속 로테이션함
* K-Fold Cross Validation 의 알고리즘
** 풀 데이터 셋을 k 와 동일한 크기의 파티션으로 나눔
*** k-1 개의 파티션을 트레이닝 셋으로 고름
*** 다른 남은 파티션을 테스트 셋으로 고름
** 트레이닝 셋으로 모델을 학습시킴
** 학습된 모델로 테스트 셋을 예측함
** 에러 메트릭을 계산
** 위 단계를 k-1번 반복
** K 개의 에러 값의 평균을 계산

* Holdout Validation은 K-Fold Cross Validation에서 K = 2일때 버전임
* 일반적으로 K-Fold Cross Validation에서는 K = 5 or 10을 사용함

* fold 수를 늘리면 각 폴드에서의 관측 수가 감소하고 fold-by-fold 에러 분산이 증가함


== 4. First Iteration
* fold 1을 테스트 셋으로 2~5를 트레이닝 셋으로 이용

== 5. 훈련 모델을 위한 함수
* 4장에서 했던 내용을 반복적으로 변경 (평균 RMSE 값 계산)

== 6. Scikit-Lean 을 사용한 K-Fold Cross Validation 수행
* RMSE 값 사이의 큰 변동은 열악한 모델, 열악한 평가 기준을 사용하고 있음을 의미
* 머신러닝에서 좋은 모델을 만들고 그 모델이 얼마나 잘 수행되는지 정확히 이해하는데 관심을 둔다.
* K-Nearest Neighbor 에서는 속성을 늘려보고 K값을 변동한 것처럼 K-Fold Cross Validation 에서는 적절한 폴드 수를 선택 할 수 있다.

== 7. 다양한 K 값 탐험
* Holdout Validation 의 K 값은 2
* K를 n(데이터 세트의 관측수)와 같게 설정하는 것은 leave-one-out cross validation(LOOCV) 이라고 함
* 시행착오를 거쳐 데이터 과학자들은 표준 K값을 10으로 수렴
* demo 코드에서 K를 3 ~ 23으로 설정 후 결과를 표시
* 각 K값에 대해 평균 RMSE값과 RMSE 값의 표준 편차를 계산

== 8. Bias-Variance Tradeoff
* RMSE가 낮으면 모델이 더 정확하다는 가정하에 작업해왔지만 그건 완전하지 않다.
* 모델에는 오차, 분산의 두가지 원인이 있음
* Bias ?
** 학습 알고리즘에 대한 잘못된 가정을 초래하는 오류를 뜻한다.
** 예를 들어, 자동차의 무게와 같은 단 하나의 기능이 자동차의 연료 효율과 관련있다고 가정하면 높은 bias를 나타내는 단순하고 단변량 회귀모델에 적합하게 됨
* 편차는 모델의 예측된 값의 가변성때문에 발생하는 오류를 뜻한다.
** 각 자동차에 1000개의 속성이 있는 데이터 셋을 제공하고 모든 단일 속성을 사용하여 엄청나게 복잡한 다중 변수 회귀모델을 학습하면 bias는 낮지만 분산이 높다.
* 이상적으로 낮은 편차와 bias를 원하지만 실제로는 상충 관계에 있음

* RMSE 값의 표준편차는 모델의 분산에 대한 프록시, 평균 RMSE는 모델의 bias에 대한 프록시

* k-nearest neighbor는 예측할순 있지만 수학적이진 않다.
* 다음 두 코스에서는 선형회귀를 배울 예정, 이때 bias-variance tradeoff 를 깊이있게 탐구할 예정

== 9. Next Steps


== 예제

=== 1.

[source,python]
----
import numpy as np
import pandas as pd

dc_listings = pd.read_csv("dc_airbnb.csv")
stripped_commas = dc_listings['price'].str.replace(',', '')
stripped_dollars = stripped_commas.str.replace('$', '')
dc_listings['price'] = stripped_dollars.astype('float')

shuffled_index = np.random.permutation(dc_listings.index)
dc_listings = dc_listings.reindex(shuffled_index)
split_one = dc_listings[0:1862]
split_two = dc_listings[1862:]
----

=== 2.

[source,python]
----
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from math import sqrt


train_one = split_one
test_one = split_two
train_two = split_two
test_two = split_one

knn = KNeighborsRegressor()

def calculateRMSE(train, test):
    knn.fit(train[['accommodates']], train['price'])
    test['predicted_price'] = knn.predict(test[['accommodates']])
    return sqrt(mean_squared_error(test['price'], test['predicted_price']))

iteration_one_rmse = calculateRMSE(train_one, test_one)
iteration_two_rmse = calculateRMSE(train_two, test_two)

avg_rmse = np.mean([iteration_two_rmse, iteration_one_rmse])
----

=== 3.

[source, python]
----
dc_listings.set_value(dc_listings.index[0:744], "fold", 1)
dc_listings.set_value(dc_listings.index[744:1488], "fold", 2)
dc_listings.set_value(dc_listings.index[1488:2232], "fold", 3)
dc_listings.set_value(dc_listings.index[2232:2976], "fold", 4)
dc_listings.set_value(dc_listings.index[2976:3723], "fold", 5)
----

=== 4.

[source,python]
----
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

# Training
model = KNeighborsRegressor()
train_iteration_one = dc_listings[dc_listings["fold"] != 1]
test_iteration_one = dc_listings[dc_listings["fold"] == 1]
model.fit(train_iteration_one[["accommodates"]], train_iteration_one["price"])

# Predicting
labels = model.predict(test_iteration_one[["accommodates"]])
test_iteration_one["predicted_price"] = labels
iteration_one_mse = mean_squared_error(test_iteration_one["price"], test_iteration_one["predicted_price"])
iteration_one_rmse = iteration_one_mse ** (1/2)
----


=== 5.

[source,python]
----
# Use np.mean to calculate the mean.
import numpy as np
fold_ids = [1,2,3,4,5]
def train_and_validate(df, folds):
    fold_rmses = []
    for fold in folds:
        # Train
        model = KNeighborsRegressor()
        train = df[df["fold"] != fold]
        test = df[df["fold"] == fold]
        model.fit(train[["accommodates"]], train["price"])
        # Predict
        labels = model.predict(test[["accommodates"]])
        test["predicted_price"] = labels
        mse = mean_squared_error(test["price"], test["predicted_price"])
        rmse = mse**(1/2)
        fold_rmses.append(rmse)
    return(fold_rmses)

rmses = train_and_validate(dc_listings, fold_ids)
print(rmses)
avg_rmse = np.mean(rmses)
print(avg_rmse)
----


=== 6.

[source,python]
----
from sklearn.cross_validation import KFold
from sklearn.cross_validation import cross_val_score

kf = KFold(len(dc_listings), 5, shuffle=True, random_state=1)
model = KNeighborsRegressor()
mses = cross_val_score(model, dc_listings[["accommodates"]], dc_listings["price"], scoring="mean_squared_error", cv=kf)
rmses = [np.sqrt(np.absolute(mse)) for mse in mses]
avg_rmse = np.mean(rmses)
----


=== 7. demo

[source,python]
----
from sklearn.cross_validation import KFold
from sklearn.cross_validation import cross_val_score
num_folds = [3, 5, 7, 9, 10, 11, 13, 15, 17, 19, 21, 23]

for fold in num_folds:
    kf = KFold(len(dc_listings), fold, shuffle=True, random_state=1)
    model = KNeighborsRegressor()
    mses = cross_val_score(model, dc_listings[["accommodates"]], dc_listings["price"], scoring="mean_squared_error", cv=kf)
    rmses = [np.sqrt(np.absolute(mse)) for mse in mses]
    avg_rmse = np.mean(rmses)
    std_rmse = np.std(rmses)
    print(str(fold), "folds: ", "avg RMSE: ", str(avg_rmse), "std RMSE: ", str(std_rmse))
----
