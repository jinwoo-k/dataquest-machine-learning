= Cross Validation

Learn how to use k-fold cross validation to perform more rigorous testing.

== 1. Introduction
* 기존 미션에서는 train/test validation 를 배웠고, 이번 미션에서는 좀 더 견고한 테크닉을 배울 것이다.
* 먼저 holdout validation 기술에 대해 시작한다.
1. 전체 데이터셋을 두개의 파티션으로 구분한다. => training set / test set
2. training set 을 이용해 모델을 학습시킨다.
3. 학습된 모델을 이용해 test set에 대해 예측한다.
4. 모델의 효과를 파악하기 위해 error metric을 계산한다.
5. training set 과 test set을 바꿔 반복한다.
6. 에러를 평균낸다.
* holdout validation 에서는 75/25 대신 50/50 으로 train/test set을 분할한다.

== 2. Holdout Validation
* 실제로 holdout validation을 수행하는 절차
[source,python]
----
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

features = ['accommodates']
def get_rmse(train, test):
    knn = KNeighborsRegressor()
    knn.fit(train[features], train['price'])
    prediction = knn.predict(test[features])
    mse = mean_squared_error(test['price'], prediction)
    return numpy.sqrt(mse)


train_one = split_one
test_one = split_two
train_two = split_two
test_two = split_one

iteration_one_rmse = get_rmse(train_one, test_one)
iteration_two_rmse = get_rmse(train_two, test_two)
print(iteration_one_rmse)
print(iteration_two_rmse)
avg_rmse = numpy.mean([iteration_one_rmse, iteration_two_rmse])
----

== 3. K-Fold Cross Validation
* Holdout validation 은 K-Fold cross validation 에서 K값이 2인 특정 케이스이다.
* K-Fold 교차검증 알고리즘
1. 데이터 셋 준비 : 데이터셋을 k개로 분할 하고 k-1개 파티션을 training set으로, 나머지 하나를 test set으로 사용한다.
2. training set 을 이용해 모델을 학습시킨다.
3. 학습된 모델을 이용해 test set에 대해 예측한다.
4. 모델의 효과를 파악하기 위해 error metric을 계산한다.
5. training set 과 test set을 바꿔 k-1회 반복한다.
6. 에러를 평균낸다.
* 일반적으로 k 값을 5 또는 10으로 사용한다.

== 4. First Iteration
* 단 변수 모델에서 k-fold 교차 검증의 첫 번째 반복을 수행한다.

[source,python]
----
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

features = ['accommodates']
def get_rmse(train, test):
    knn = KNeighborsRegressor()
    knn.fit(train[features], train['price'])
    prediction = knn.predict(test[features])
    mse = mean_squared_error(test['price'], prediction)
    return numpy.sqrt(mse)

training_set = dc_listings.loc[(1 < dc_listings.fold)]
test_set = dc_listings.loc[(dc_listings.fold == 1)]

iteration_one_rmse = get_rmse(training_set, test_set)
----

== 5. Function For Training Models
* 각각의 fold 에 대해 rmse들을 반환해주는 함수를 작성해 이용한다.
[source,python]
----
import numpy as np
fold_ids = [1,2,3,4,5]

features = ['accommodates']
def get_rmse(train, test):
    knn = KNeighborsRegressor()
    knn.fit(train[features], train['price'])
    prediction = knn.predict(test[features])
    mse = mean_squared_error(test['price'], prediction)
    return np.sqrt(mse)

def train_and_validate(df, folds):
    rmses = []
    for fold in folds:
        train_set = df.loc[df.fold != fold]
        test_set = df.loc[df.fold == fold]
        rmses.append(get_rmse(train_set, test_set))

    return rmses

rmses = train_and_validate(dc_listings, fold_ids)
avg_rmse = np.mean(rmses)
print(rmses, avg_rmse)
----

== 6. Performing K-Fold Cross Validation Using Scikit-Learn
* 각 RMSE 값 사이의 차이가 큰 경우 모델이 안좋거나 평가 기준이 안좋다는 것을 의미한다.
* 이를 줄이기 위해 데이터 프레임의 행 순서를 무작위로 지정하고 폴드로 분할을 처리 할 수수 있다.
* 더 나은 KNN 모델을 만들기 위해 K값(hyperparameter)을 조정하거나 feature를 변경한다.
* 모델의 성능에 대한 정확도를 잘 이해하기 위해 k-fold 교차검증을 수행하고 적절한 k값 을 선택한다.
* 위의 두가지를 쉽게 다루기 위해 scikit-learn 을 이용해보도록 하자
[source,python]
----
from sklearn.cross_validation import KFold
from sklearn.cross_validation import cross_val_score

features = ['accommodates']

kf = KFold(dc_listings.size, 5, shuffle=True, random_state=1)
knn = KNeighborsRegressor()
mses = cross_val_score(knn, dc_listings[features], dc_listings['price'], scoring = 'mean_squared_error')
avg_rmse = numpy.sqrt(numpy.mean(mses))
----

== 7. Exploring Different K Values
* K 값이 2인 holdout validation 부터 K 값이 데이터세트 크기 N 인 leave-one-out cross validation(LOOCV)까지 있다.
* 데이터 과학자들 사이에 K의 일반값으로 10으로 수렴했다.
* K를 3부터 23까지 변경했을때 rmse 의 평균과 표준편차로부터 어떤 K값이 적절한지 파악함

== 8. Bias-Variance Tradeoff
* 모델의 에러는 편향과 분산으로부터 발생한다.
* 편차(bias)와 분산(variance)는 tradeoff 관계에 있다.
* 편차는 학습 알고리즘에 대한 잘못된 가정을 초래
* 분산은 예측된 값의 다양성으로 발생
* KNN은 예측을 할 수 있지만 수학적 모델은 아님
* 수학적 모델은 일반적으로 원래 데이터없이 존재할 수 있는 방정식
* 다음장에서 선형 회귀라는 수학적 모델에 대해 다룸
