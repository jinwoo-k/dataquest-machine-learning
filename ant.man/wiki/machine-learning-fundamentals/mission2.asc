== Evaluating Model Performance ==


=== 1: Testing Quality Of Predictions

> test vs tranining

image:https://s3.amazonaws.com/dq-content/train_test_split.png[width="500px"]

train/test validation :
process 1. training set / test set 2. training set 의 값을 통해 test set 의 값 예측. 3. 예상값과 실제 값 비교

2. error metric.
an error metric quantifies how inaccurate our predictions were from the actual values
> MAE (mean absolute error) = ( | acutal(1) - pre(1) | + ... + | acutal(n) - pre(n) | ) / n

> MSE (mean squared error) = ( (acutal(1) - pre(1))^2 + ... + (acutal(n) - pre(n))^2 ) / n


4: Training Another Model
위에 나온 mse가 낮은지 높은지 모르기 때문에 다른걸 트래이닝 시켜 서로 값을 비교한다.

rmse = mse ** (1/2)

### 7: Next Steps
<다음 두 장 예고>

k 값의 최적화를 통해 모델의 효율을 높인다

<비고>
오차(Error) : 예측값과 "참값" 의 차
편차(Deviation) : 자료값과 "평균" 의 차
앞으로 MAE, MSE, RMSE 를 배우게 되는데 MAD, MSD, RMSD도 있다. MSD는 분산, RMSD는 표준편차.
MAD는 평균절대편차 라고 하는데 표준편차가 산술평균에 대한 편차를 나타낸다면 MAD는 중앙값에 대한 편차를 뜻한다
