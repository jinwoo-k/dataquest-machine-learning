== Intermediate linear regression
=== 1. Introduction to the Data
* 피사의 사탑 예: 해당 연도에 타워가 축을 벗어난 미터수
`plt.scatter(pisa["year"], pisa["lean"])`
image:./images/pisa_year_lean.png[]

=== 2.Fit the Linear Model
* 이전 그래프를 봤듯이 선형회귀가 적합
** 선형 회귀 모델의 주요 통계 개념 배울 예정
** http://www.statsmodels.org/stable/index.html[Statsmodels] : 파이썬용 정밀한 통계 분석용 라이브러리 (선형회귀에 적합)
* sm.OLS 클래스: OLS 의 맞게 사용됨
* 초기화 후 fit() 으로 데이터를 모델에 맞춤
** OSL 는 절편을 자동으로 안줌 -> add_constant 사용 (x의 계수가 아닌 1의 계수를 따로 추가)
```
import statsmodels.api as sm

y = pisa.lean # target, equal to pisa["lean"]
X = pisa.year  # features
X = sm.add_constant(X)  # add a column of 1's as the constant term

# OLS -- Ordinary Least Squares Fit
linear = sm.OLS(y, X)
# fit model
linearfit = linear.fit()

print(linearfit.summary())
```

=== 3. Define a Basic Linear Model
* 공식 정의: image:./images/basic_formula.png[]
** 절편 + 기울기 + 각 값(관측)의 에러를 뜻함
** ei 는 실제값과 예측값의 차이
** N(0,σ2): 평균 0, 분산 σ2를 갖는 정규분포
** ei~N(0,σ2) 뜻: 예측값과 실제값의 차가 정규분포이며 평균 0으로 가정함
* image:./images/estimate_formula.png[]
** 마찬가지로 위는 추정된 계산식 (위에 ^ 는 모두 추청,예측이라는 뜻)

```
# Our predicted values of y
yhat = linearfit.predict(X)
print(yhat)

residuals = yhat - y # pisa["lean"] , pisa.lean
```

=== 4. Histogram of Residuals
* 잔차의 히스토그램을 보고 (시각화하여) 오류가 괜찮을지 확인
** 일반적으로 종과 같은 곡선과 같은 모양일때 좋음
** 추후 일반적인 엄격한 테스트 배움
* `plt.hist(residuals, bins=5)`  ref: http://matplotlib.org/api/pyplot_api.html?highlight=hist#matplotlib.pyplot.hist[hist()]
** bins 를 통해 구간을 몇개로 나눠서 볼지 정함
image:./images/histograms.png[]

=== 5. Interpretation of Histogram
* 13개만으론 해석 힘듦, 가장 많은게 4개라서 이전에 했던 가정이 맞다고 그냥 넘김 -> 가정했던 평균, 분산을 말하는 듯

=== 6. Sum of Squares
* 많이 사용되는 제곱합 측정 3가지, 이 값들은 전체 모델의 분산을 설명함.
** SSE (Sum of Square Error)
*** image:./images/SSE.png[]
*** 간단히, 에러와 실제값 차이의 제곱합
** RSS (Regression Sum of Squares)
*** image:./images/RSS.png[]
*** 관측치와 예측치 사이의 분산
*** 예측값이 모두 평균이면 RSS는 매우 낮지만 필요없는 모델이다. (예측해봤자 평균이니까..)
*** 따라서, RSS 는 크고, SSE가 작아야 강력한 모델이다. (당연함. 예측한 값들이 평균에없고 -> 다 제각각이고, 막상 예측과 실제값의 차이는 적기 때문)
** TSS (Total Sum of Squares)
*** image:./images/TSS.png[]
*** 전체 변동량

* TSS = SSE + RSS

```
ymean=(np.sum(y.values)/len(y)) # np.mean(y.values)

SSE = np.sum((y.values-yhat)**2)
RSS = np.sum((ymean - yhat)**2)
TSS = np.sum((y.values-ymean)**2)
```

=== 7. R-Squared
* R-Squared: 선형 방정식의 척도로 쓰이는 결정계수, 목표 변수의 변동 비율이 모델에 의해 얼마나 잘 설명되는지를 뜻함
** image:./images/rsquare.png[]
** 낮은 SSE와 높은 RSS가 잘 맞음
** 0과 1 사이의 값을 가지며 1에 가까울수록 좋은 결과임
** `R2 = 1- SSE/TSS # R2 = RSS/TSS`

=== 8. Interpretation of R-Squared
* 0.988 .. ->   데이터 내에서 98.8% 내의 변량을 따른다 (목표값과 98% 맞다의 뜻인듯)

=== 9. Coefficients of the Linear Model
* 선형모델의 장점은 다른 복잡한 모델보다 계수를 이해하고 해석할 수 있는 능력이 크다는 점
** 계수의 신뢰도를 측정하는 방법
*** 우리가 fit 했던 `linear = sm.OLS(y, X) linearfit = linear.fit() linearfit.summary()` 결과에 여러 통계치
image:./images/OLS_result.png[]

*** 계수 그 차제를 살피기
**** 기울기는 변화량 (예를들어 피사의 예제로는 년도마다 몇미터 기울어지는지를 의미)
```
#linearfit.params["year"] * 15 + linearfit.params["const"]
delta = linearfit.params["year"] * 15
```

=== 10. Variance of Coefficients
* 각 계수의 분산은 아주 중요한 척도
** 이 예제에선 년도의 계수가 매년 기우는 미터를 나타냄
** 이전에 봤던 summary() 의 결과에서 각 계수의 에러값이 옆에 나타남
** image:./images/coeffi_variable.png[]
** 분자항: 작은 오류(SSE가 낮음)은 계수의 분산을 감소시킴
** 분모향: x 내에서 분산의 양 측정, 독립변수의 큰 차이는 계수의 분산을 감소시킴
** 이 분산을 이용해 t-statistics 와 신뢰구간 계산가능
```
SSE = np.sum((y.values - yhat)**2)
xvar = np.sum((pisa.year - pisa.year.mean())**2)
s2b1 = SSE / ((len(y) - 2) * xvar)
```

=== 11. T-Distribution
* 타워의 경사가 년도에 달려있다 라는 것은 통계 테스트로 볼 수 있음
* "student t-test"
** 일반적인 통계 test 이고 이건 t-distribution(분포) 에 의존적
** 정규분포와 비슷하지만 낮은 피크가 더 낮다
** 표본 집합의 관측치 수는 t-distribution을 설명하는 반면 정규 분포는 전체 집합을 뜻함
** 관측수가 적으면 전체에 대한 결과아 달라짐 -> 분산을 증가시켜서 어느정도 해결
** 유의성 검정에는 t-분포의 밀도 함수가 사용
*** 확률 밀도 함수(pdf)는 연속 확률 변수의 상대적 가능성을 모델링
*** 누적 밀도 함수(cdf)는 확률 변수가 한 점보다 작거나 같을 확률을 모델링
*** 자유도 (df)는 표본의 관측 수를 나타냄 (일반적으로 df 는 N-2)
**** 딱 2개만 관측되었을 떄, 완벽한 선하나만 만들고 오류가 없기 때문에 N-2 를 기본적으로 함

* scipy.stats.t 라이브러리
** 자유도와 관계없이 t-distribution의 pdf, cdf 계산
* scipy.stats.t.pdf(x,df) : df 의 자유도가있는 변수 x의 pdf를 추정하는 데 사용

```
print(t.pdf(x=x, df=3))

tdist3 = t.pdf(x=x, df=3)
tdist30 = t.pdf(x=x, df=30)

# Plot pdfs
plt.plot(x, tdist3) # 파랑 :
plt.plot(x, tdist30) # 초록 :
```
image:./images/tdis_3vs30.png[]

=== 12. Statistical Significance of Coefficients
* t-distribution 로 중요도 테스트
** 귀무 가설로 가정, 년도와 기울기는 관계없다고 하며, 계수가 0이라고 함
** 대체가설은 탑의 기울기가 연도와 관계가 있다는 것이며, 그 계수가 0이 아님
*** image:./images/hypotheses.png[]
** 귀무가설 테스트, T-Distribution 사용하여 null 테스트. t-statistic 정의는 아래와 같음
*** image:./images/test_hypo.png[]
**** 이 통계량은 기대 계수가 0에서부터 얼마나 많은 표준편차를 갖는지 측정
**** β1이 0 일 때 분산이 낮으면 t는 매우 높아짐
**** pdf에서 볼 수 있듯이 0에서 멀리 떨어진 t-통계량은 매우 낮은 확률을 갖게 됨
*** `tstat = linearfit.params["year"] / np.sqrt(s2b1) # 30.06`

=== 13. The P-Value
* t-statistic 계산을 보았으므로 계수를 테스트 할 수 있음
* 계수 테스트: 어떤 수준에서 β1 이 0이 아닌 확률 찾기 (우리는 95% 사용)
** t-distribution 를 통해 수행, p-value (95%) 와 자유도의 누적 밀도로 해당 확률 계산
* 선형 회귀 계수에는 계수가 0보다 작고 0보다 큰지 여부를 테스트하는 양면 테스트를 사용해야 함
** 예: 타워의 연간 기우는 미터 수는 양수 또는 음수 일 수 있음, 둘다 확인 필요!
** t-distribution는 0에 대해 대칭이므로 절대 값을 취해서 97.5 백분위 수에서만 테스트 가능
** 확률이 0.975보다 크면 귀무가설(H0)를 거부하고 그 해가 타워의 기울기에 유의미한 영향을 미친다고 할 수 있음

* image:./images/hypo_test.png[width=210,height=100]

```
pval = 0.975

# The degrees of freedom
df = pisa.shape[0] - 2

# The probability to test against
p = t.cdf(tstat, df=df)
beta1_test = p > pval
```
=== 14. next step
