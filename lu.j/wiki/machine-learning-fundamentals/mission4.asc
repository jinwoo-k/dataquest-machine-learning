# Hyperparameter Optimization

## 1. 요점 되풀이
* 지난 미션에서 속성을 선택해서 모델의 정확도를 향상시키는 방법을 살펴봄
** 사용 가능한 모든 속성을 써도 정확도가 향상되지는 않음
** 일부 속성은 유사성 순위와 관련이 없는 것으로 보임
** 관련된 속성을 선택하는 것이 정확성을 향상시킬수 있음

* 이 미션에서는 K값이 증가할때의 영향에 초점을 맞춤

## 2. Hyperparameter 최적화
* 모델에 속성을 다양하게 만들면 데이터에 영향이 미친다.
* 반면에 K값은 예측할 때 사용되는 실제 데이터와는 독립적으로 모델의 동작에 영향을 준다.
* 데이터 변경을 하지 않고 모델이 수행하는 방식에 영향을 준다.

* HyperParameter란 ?
=> 사용되는 데이터와 관련이 없는 모델의 동작 및 성능에 영향을 미치는 값
* HyperParameter 최적화란 ?
=> 최적의 HyperParameter를 찾는 프로세스
* 일반적인 HyperParameter 최적화 기법 => 그리드 검색
** 가능한 HyperParameter 값의 서브 셋 선택
** 각 HyperParameter 값을 사용하여 모델 학습
** 각 모델의 성능평가
** 가장 낮은 오류값의 HyperParameter 선택

* 그리드 검색은 기본적으로 다른 K값에서 모델 성능을 평가하고 가장 낮은 오류 값이 결과인 K를 선택한다.
* 대규모 데이터로 작업할때는 그리드 검색이 느림

* 예제에서는 K값을 1 ~ 5로 변화시키며 모델의 성능을 비교함
* 가장 정확도가 좋았던 속성값을 이용함

## 3. 그리드 검색 확장
* 그리드 검색을 K값이 20일때까지 확장
* 가장 낮은 MSE값이 우리가 지금까지 시도한 HyperParameter 값 중 하나와 관련이 있다는걸 확신하지 못하면 시도값을 확장할 수 있다.

## 4. HyperParameter 값 시각화
* 이제까지 시도한 K값 중에 6이 가장 MSE가 작았기 때문에 최적의 값으로 볼수 있다.
* K를 처음으로 올리면 오류율은 특정 시점까지 감소하지만 다시 반동하여 증가한다.

## 5. 다양한 속성들과 HyperParameter
* K값을 변화시키면 MSE 값이 감소
* K를 5로 고정한 뒤 가능한 모든 feature를 선택한 모델로 그리드 검색 프로세스 반복

## 6. 워크플로우 연습
* 가장 좋은 모델을 찾는 워크플로우는 아래와 같다.
** 타겟 열을 예측하는데 사용할 관련 속성 선택
** 그리드 검색을 사용하여 선택한 속성에 대한 최적의 HyperParameter 값을 찾는다.
** 모델의 정확성을 평가하고 프로세스를 반복한다.

## 7. Next Steps
* 객실, 침실, 욕실 및 리뷰 수 열을 사용했을 때 전체 속성을 선택한 경우보다 더 좋음


## 예제 모음

### 1.

[source,python]
```
import pandas as pd

train_df = pd.read_csv("dc_airbnb_train.csv")
test_df = pd.read_csv("dc_airbnb_test.csv")
```

### 2. 

[source,python]
```
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']
hyper_params = [1, 2, 3, 4, 5]
mse_values = list()

for hp in hyper_params:
    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')
    knn.fit(train_df[features], train_df['price'])
    predictions = knn.predict(test_df[features])
    mse = mean_squared_error(test_df['price'], predictions)
    mse_values.append(mse)
```

### 3.
 
[source,python]
```
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']
mse_values = list()

for hp in range(1, 21):
    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')
    knn.fit(train_df[features], train_df['price'])
    predictions = knn.predict(test_df[features])
    mse = mean_squared_error(test_df['price'], predictions)
    mse_values.append(mse)
```

### 4.

[source,python]
```
import matplotlib.pyplot as plt
%matplotlib inline

features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']
hyper_params = [x for x in range(1, 21)]
mse_values = list()

for hp in hyper_params:
    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')
    knn.fit(train_df[features], train_df['price'])
    predictions = knn.predict(test_df[features])
    mse = mean_squared_error(test_df['price'], predictions)
    mse_values.append(mse)
   
plt.scatter(x=hyper_params,y=mse_values)
plt.show()
```

### 5. 

[source,python]
```
import matplotlib.pyplot as plt
%matplotlib inline

features = train_df.columns.tolist()
features.remove('price')
hyper_params = [x for x in range(1, 21)]
mse_values = list()

for hp in hyper_params:
    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')
    knn.fit(train_df[features], train_df['price'])
    predictions = knn.predict(test_df[features])
    mse = mean_squared_error(test_df['price'], predictions)
    mse_values.append(mse)
   
plt.scatter(x=hyper_params,y=mse_values)
plt.show()
```

### 6.

[source,python]
```
two_features = ['accommodates', 'bathrooms']
three_features = ['accommodates', 'bathrooms', 'bedrooms']
hyper_params = [x for x in range(1,21)]
# Append the first model's MSE values to this list.
two_mse_values = list()
# Append the second model's MSE values to this list.
three_mse_values = list()
two_hyp_mse = dict()
three_hyp_mse = dict()
for hp in hyper_params:
    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')
    knn.fit(train_df[two_features], train_df['price'])
    predictions = knn.predict(test_df[two_features])
    mse = mean_squared_error(test_df['price'], predictions)
    two_mse_values.append(mse)

two_lowest_mse = two_mse_values[0]
two_lowest_k = 1

for k,mse in enumerate(two_mse_values):
    if mse < two_lowest_mse:
        two_lowest_mse = mse
        two_lowest_k = k + 1
    
for hp in hyper_params:
    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')
    knn.fit(train_df[three_features], train_df['price'])
    predictions = knn.predict(test_df[three_features])
    mse = mean_squared_error(test_df['price'], predictions)
    three_mse_values.append(mse)
    
three_lowest_mse = three_mse_values[0]
three_lowest_k = 1

for k,mse in enumerate(three_mse_values):
    if mse < three_lowest_mse:
        three_lowest_mse = mse
        three_lowest_k = k + 1

two_hyp_mse[two_lowest_k] = two_lowest_mse
three_hyp_mse[three_lowest_k] = three_lowest_mse
```
