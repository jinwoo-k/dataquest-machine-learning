== Cross Validation

 * Train/Test 유효성 검사
   ** 전체 Set 을 두개로 나눔 (학습 / 테스트)
   ** 학습 셋을 이용하여 모델을 훈련시키고 훈련된 모델을 이용하여 테스트셋으로 예측
   ** 모델의 유효성을 판단하기 위해 예측된 값을 이용하여 error metric 을 계산
   ** 학습, 테스트 셋을 변경하여 반복
   ** 에러들의 평균 ?

 * holdout validation
   ** Train:Test Set 비율을 75:25 대신 일반적으로 50:50 사용
   ** 학습, 테스트 셋을 변경하여 평균을 냄
   ** K-Fold Cross Validation 유효성 검증 기법의 한 예
   ** K 개로 나누어 K-1 개를 Train 셋으로 하나를 Test 셋으로 구분하고 Shift 하면서 K 번 처리하여 평균
   ** RMSE 값의 분포가 큰 범위에 걸쳐 있으면 모델이 적합하지 않음을 나타냄

image:https://s3.amazonaws.com/dq-content/kfold_cross_validation.png[]

 * 함수 생성에 대한 예 : *def name(params):* ... indent ... *return(value)*

 * Scikit-Learn 을 이용한 단순 처리 기법
     1. K-Fold 정의
     2. model 정의 : KNN Model KNeighborsRegressor()
     3. corss_val_score 를 이용하여 mse 들을 구함
     4. rmses 계산
     4. average_rmse 계산

 * 위에서 배운 K-Fold 를 간단히 처리하는 방법을 이용하여 다양한 K 값에 대한 RMSE 의 추이를 살펴본다.
 * K 값을 데이터 셋트와 동일하게 만드는 경우 LOOCV (Leave-one-out cross validation) 라 함

 * Error 의 정의 : Error = noise + bias + variance
   ** noise는 데이터가 가지는 본질적인 한계치로 irreducible error
   ** bias/variance는 모델에 따라 변하는 것이기에 reducible error

 * 데이터가 가지고 있는 불확실성이나 noise 뿐만 아니라 모든 학습 알고리즘은 두 가지 종류의 에러를 가진다.
 * Bias 와 Variance TradeOff
   ** 기존 RMSE 에 의존하여 정확성을 판단하는것이 정답은 아님
   ** RMSE 값의 표준 편차는 모델의 분산에 대한 프록시 일 수 있으며 평균 RMSE는 모델의 바이어스에 대한 프록시
   ** Bias (편향, 탄착군 형성 ;;)
      *** 학습 알고리즘에 사용된 Feature 설정이 잘못된 것에 대한 설명 (가정에 대한 오류 판단)
      *** 데이터 내에 있는 모든 정보를 고려하지 않음으로 인해, 지속적으로 잘못된 것들을 학습하는 경향을 말함
      *** underfitting 과 관계
   ** Variance (퍼짐, 사방팔방 ? ;;)
      *** 모델의 예측값의 다양성에 의해 발생하는 오류를 설명
      *** 데이터 내에 있는 에러나 노이즈까지 잘 잡아내는 highly flexible models 에 데이터를 fitting시킴으로써 실제 현상과 관계 없는 random한 것들까지 학습하는 알고리즘의 경향을 의미
      *** overfitting 과 관계

   ** 이상적인 모델은 데이터의 규칙성을 잘 잡아내어 정확하면서도 다른 데이터가 들어왔을 때도 잘 일반화할 수 있는 모델임
   ** 하지만, 실제 상황에서는 두 가지를 동시에 만족하는 것은 거의 불가능하며 따라서 트레이닝 데이터가 아닌 실제 데이터에서
      좋은 성능을 내기 위해 이런 tradeoff는 반드시 생길 수 밖에 없으며 이를 bias-variance trade-off 라고 불린다.

image:http://cfile3.uf.tistory.com/image/261FE83B562DFB681E2F83[]

image:https://s3.amazonaws.com/dq-content/bias_variance.png[]

 * k-nearest negihbors는 예측을 할 수 있지만 수학적 모델은 아니며, 수학적 모델이라 함은 일반적으로 원래의 데이터없이 존재할 수있는 방정식을 말함

== pandas/numpy 활용 주요 function
 * function
   ** 작업
     *** shuffled_index = np.random.permutation(dc_listings.index)
         dc_listings = dc_listings.reindex(shuffled_index)
     *** iloc[start:end] : data 에서 (start <= data < end) 의 조건을 만족하는 데이터 추출, end 가 없는 경우 해당 row 이후 모두 반환
     *** dc_listings.set_value(dc_listings.index[0:744], "fold", 1) : 0 row 에서 743 row 까지 fold 필드에 1 값 셋팅
     *** np.mean, np.std, np.sbsolute, np.sqrt
     *** train_iteration_one = dc_listings[dc_listings["fold"] != 1]
     *** 기본적으로 indent 로 scope 를 처리함
     *** def train_and_validate(df, folds): 함수 선언 예
            fold_rmses = [] : 빈 배열 선언
            for...
               ...
            return(fold_rmses)

== sklearn lib (K-Fold 실행을 간단하게)
 * 라이브러리 사용 선언
   ** from sklearn.neighbors import KNeighborsRegressor
   ** from sklearn.cross_validation import KFold
   ** from sklearn.cross_validation import cross_val_score
 * function
   ** K-Fold 사용 예 사용 순서
     1. K-Fold 정의
        *** kf = KFold(len(dc_listings), 5, shuffle=True, random_state=1)
        *** KFold( 데이터셋트 수, 이웃 수, 셔플 여부, 셔플인경우 씨드값 )
     2. model 정의 : KNN Model KNeighborsRegressor()
        *** model = KNeighborsRegressor()
     3. corss_val_score 를 이용하여 mse 들을 구함
        *** cross_val_score(model, dc_listings[["accommodates"]], dc_listings["price"], scoring="mean_squared_error", cv=kf)
        *** cross_val_score( sklearn 모델, 트레이닝할 Feature 배열, 예측 열, 추출할 값 지정(문자열), 폴드정의 )
        *** http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html
     4. rmses 계산
        *** rmses = [np.sqrt(np.absolute(mse)) for mse in mses]
     4. average_rmse 계산
        *** avg_rmse = np.mean(rmses)

== 참고자료
 * https://brunch.co.kr/@chris-song/32
 * http://bywords.tistory.com/entry/%EB%B2%88%EC%97%AD-%EC%9C%A0%EC%B9%98%EC%9B%90%EC%83%9D%EB%8F%84-%EC%9D%B4%ED%95%B4%ED%95%A0-%EC%88%98-%EC%9E%88%EB%8A%94-biasvariance-tradeoff
 * http://softgearko.blogspot.kr/2014/04/machine-learning-1-cross-validation.html
