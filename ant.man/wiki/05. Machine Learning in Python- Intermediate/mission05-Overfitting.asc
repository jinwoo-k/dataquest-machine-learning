== Overfitting
=== 1. Introduction
* overfitting 식별방법과 어떻게 피할지
** 연료의 효율성에 영향을 주는 7개 feature 예제

=== 2. Bias and Variance
* overfitting: 편향과 분산을 이해 -> 2가지 오류 원인을 구성함
** 편향: 학습 알고리즘에 대한 잘못된 가정을 초래하는 오류
*** 예: 무게하나만 자동차 연료효율과 관계있다고 가정하면 단순한고 단일 회귀에 적합하게 됨
** 분산: 예측된 값의 다양성 때문에 발생하는 오류
* 낮은 편향과 낮은 분산을 원하지만, 상충관계임

=== 3. Bias-variance tradeoff
* overfit 과 편향,분산의 관계
** noise(소음,에러)가 관찰하지 못한 부분에 모든 과정에 있음
image:./images/bias_variance.png[]
* 동일 데이터에 서로다른 기능을 사용해 동일한 클래스 (여기선 선형회귀)에서 몇가지 모델을 학습하고 오류를 계산하여 모델의 편향을 근사치로 구할수 있음
** MAE, MSE, R2
* 먼저, 단변량 모델을 훈련시키는데 사용할 함수부터 만들기 (이걸로 편향,분산 계산 예정)
```
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

def train_and_test(cols):
    model = LinearRegression()
    features = filtered_cars[cols]
    target = filtered_cars["mpg"]

    model.fit(features, target)
    predictions = model.predict(features)

    mse = mean_squared_error(target, predictions)
    variance = np.var(predictions)
    return(mse, variance)

cyl_mse, cyl_var = train_and_test(["cylinders"])
weight_mse, weight_var = train_and_test(["weight"])
```

=== 4. Multivariate models
* 복잡한 모델도 확인
`seven_mse, seven_var = train_and_test(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year", "origin"])`

=== 5. Cross validation
* 오류의 양은 점점 줄어감 (24 -> 10, 반면 분산: 36-> 49)
* overfit 감지 방법: 샘플내 오류와 샘플외부 오류 비교 (혹은 훈련 오류를 테스트와 비교)
** 지금까지는 동일한 데이터로 오류 계산 -> 데이터가 없으므로, 교차 유효 검사 사용 (cross validation)
** 교차 오류 검사가 샘플 오류보다 훨씬 높으면 문제가 있음 -> 교육 모델이 일반화 되지 않았다는 뜻

* ref: http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html[kfold]
```
from sklearn.cross_validation import KFold
from sklearn.metrics import mean_squared_error
import numpy as np

def train_and_cross_val(cols):
    features = filtered_cars[cols]
    target = filtered_cars["mpg"]

    variance_values = []
    mse_values = []

    # KFold instance.
    kf = KFold(n=len(filtered_cars), n_folds=10, shuffle=True, random_state=3)

    # Iterate through over each fold.
    for train_index, test_index in kf:
        # Training and test sets.
        X_train, X_test = features.iloc[train_index], features.iloc[test_index]
        y_train, y_test = target.iloc[train_index], target.iloc[test_index]

        # Fit the model (by train) and make predictions (by test).
        lr = LinearRegression()
        lr.fit(X_train, y_train)
        predictions = lr.predict(X_test)

        # Calculate mse and variance values for this fold.
        mse = mean_squared_error(y_test, predictions)
        var = np.var(predictions)

        # Append to arrays to do calculate overall average mse and variance values.
        variance_values.append(var)
        mse_values.append(mse)

    avg_mse = np.mean(mse_values)
    avg_var = np.mean(variance_values)

    return(avg_mse, avg_var)

two_mse, two_var = train_and_cross_val(["cylinders", "displacement"])
three_mse, three_var = train_and_cross_val(["cylinders", "displacement", "horsepower"])
four_mse, four_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight"])
five_mse, five_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration"])
six_mse, six_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year"])
seven_mse, seven_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration","model year", "origin"])
```

=== 6. Plotting cross-validation error vs. cross-validation variance
* cross validation으로 했는데도 feature가 늘수록 MSE가 낮아짐 -> 모델이 일반화 잘됨
** 반면에 MSE 가 낮아질수록 분산이 낮아짐. -> MSE가 낮으면 복잡한 모델을 가지며, 입력값의 변동에 민감함
* ref : http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter[scatter]
** scatter(x,y,s,c)
```
import matplotlib.pyplot as plt
plt.scatter([2,3,4,5,6,7], [two_mse, three_mse, four_mse, five_mse, six_mse, seven_mse], c='red')
plt.scatter([2,3,4,5,6,7], [two_var, three_var, four_var, five_var, six_var, seven_var], c='blue')
plt.show()
```
image:./images/plt_mse_var.png[]

=== 7.Conclusion
* 고차원 다변량 모델은 더작은차원의 다변량 모델보다 overfit이지만 에러가 그리 다르지 않다.
* 가장 좋은 모델(mse가 낮은)은 50% 더 정확, 반면 모델 복잡성 증가에 따라 분산 25% 증가
** 모델의 복잡성 증가로 분사이 커짐에 따라 예측할수 없는 새로운 데이터의 성능이 증가

=== 8. Next Step
k-means 클러스터링이라는 감독되지 않은 기계 학습 기술을 살펴 봄
