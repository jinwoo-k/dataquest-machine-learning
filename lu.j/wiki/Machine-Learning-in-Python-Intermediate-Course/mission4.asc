= Intermediate linear regression

== 1. Introdution to the Data
* 피사의 사탑의 기울기를 구해라

== 2. Fit the Linear Model
* 분산형 플롯에서 선형 회귀가 데이터에 적합하다
* 이 미션에서 우리는 선형 회귀 모델의 주요 통계 개념을 이해하는 방법을 배운다.

== 3. Define a Basic Linear Model
* 모델에 대한 많은 정보가 포함되어 있음
* 기본 선형회귀 모형은 yi = B0 + B1xi + ei로 정의됨
* 여기서 B0는 절편, B1 은 기울기
* 관측지 i 에 대한 잔차는 ei = yi^ - yi, yi^는 예측값

image::./images/4-1.PNG[예측치]

== 4. Histogram of Residuals
* 과거 히스토그램을 사용해 데이터 분포를 시각화함

== 5. Interpertation of Histogram
* 데이터 셋이 단지 13개의 관측치만을 가지고 있어서 플롯을 해석하기 어려움
* 선형모델로 나아가 통계적 적합성 측정을 살펴본다.

== 6. Sum of squares
* 선형회귀 모델을 평가하는데 사용되는 많은 측정방법인 3개의 제곱합 측정이 있다.
** SSE (Sum of Square Error) : 모델의 예측과 관측된 값 사이의 측정값을 제공하는 잔차의 합계

image::./images/4-3.PNG[SSE]

** RSS (Regression Sum of Squares) : 관측치와 예측치 사이의 분산

image::./images/4-4.PNG[RSS]

** TSS (Total Sum of Squares) : 데이터 내의 전체 변동량을 측정

image::./images/4-5.PNG[TSS]

== 7. R-Squared
* R-Squared(결정 계수)는 선형 의존성의 좋은 척도
* 직관적으로 우리는 낮은 SSE와 높은 RSS가 잘 맞는 것을 나타냄
* 이 단일 척도는 우리 모델이 고려하는 데이터의 전체 변화 중 몇 퍼센트가 되는지 알려준다
* 0과 1 사이의 값을 가지며 1에 가까울수록 좋은 결과임

image::./images/4-6.PNG[R-Squared]

== 8. Interpretation of R-Squared
* R-Squared 값은 선형 모델의 경우 0.988로 데이터 내에서 98.8%를 차지

== 9. Coefficients of the Linear Model
* 계수를 이해하고 해석하는 능력은 복잡한 모형보다 선형 모형의 큰 장점이다.
* f(x) = B0 + B1x의 각 Bi 는 계수이다.
* 먼저 계수 자체를 살펴본다.
* 계수는 독립 변수의 단위 증가에 따라 종속 변수가 변경되는 정도를 측정한다.

== 10. Variance of coefficients
* 각 계수의 분산은 중요하고 강력한 측정이다
* 요약 출력에서 각 계수 옆에 표준 오류가 있는 열이 표시됨
* 표준 오차는 추정된 분산의 제곱근
* 단일 변수 선형 모델에서 추정된 분산

image::./images/4-7.PNG[분산]

*  이 공식은 우리의 추정된 B1^ 의 분산을 취함으로써 나타낼 수 있다.
* 수식에서 분자는 SSE(모델 내의 오류)를 뜻한다.

* 분모항은 x 내 분산의 양을 측정

image::./images/4-8.PNG[분산]

* 모델의 작은 오차는 계수의 분산을 감소시킴
* 분산을 사용해서 B1에 대한 t-statistics 및 신뢰구간을 계산할 수 있다.

== 11. T-Distribution
* 통계적 유의성에 대한 일반적인 테스트는 student T-test 이다.
* student t-test는 분포에 의존한다.
* 표본 집합의 관측치 수는 t-distribution을 설명하는 반면 정규 분포는 전체 집합을 뜻함
* 유의성 검정에 T-distribution의 밀도 함수가 사용됨
* 확률 밀도함수(pdf)는 연속 확률 변수의 상대우도를 모델링
* 누적 밀도함수(cdf)는 확률 변수가 한점보다 작거나 같을 확률을 모델링
* 자유도(df) : 표본의 관측수

== 12. Statistical Significance of coefficients
* 계수의 통계적 유의성에 대해 살펴본다
* 대체 가설은 타워의 기울기가 연도에 의존한다는 것 즉 계수가 0이 아닌것

image::./images/4-10.PNG[대체가설]

* 귀무가설을 테스트하는 것은 T-Distribution을 사용해서 수행됨
* T-statistics 는 다음과 같이 정의됨

image::./images/4-11.PNG[T-statistics]

== 13. The P-Value
* T-Statistics 를 계산했으므로 계수를 테스트 할 수 있다.
* 95% 유의 수준에서 B1 이 0이 아닌 확률을 구해보자
* 95% 신뢰구간에서 B1이 양수인지 음수인지 테스트 하기 위해 우리는 분포에서 2.5와 97.5 백분위 수를 관찰하여 이 값 사이에 95% 신뢰를 남김
* T-Distribution 0에 대해 대칭이므로 절대 값을 취해서 97.5 백분위 수에서만 테스트 할 수 있다.
* 확률이 0.975보다 크면 귀무가설(H0)를 거부하고 그 해가 타워의 기울기에 유의미한 영향을 미친다고 할 수 있음


== 예제

=== 1.

[source,python]
----
import pandas
import matplotlib.pyplot as plt

pisa = pandas.DataFrame({"year": range(1975, 1988),
                         "lean": [2.9642, 2.9644, 2.9656, 2.9667, 2.9673, 2.9688, 2.9696,
                                  2.9698, 2.9713, 2.9717, 2.9725, 2.9742, 2.9757]})

print(pisa)
plt.scatter(pisa["year"], pisa["lean"])
----

=== 2.

[source,python]
----
# Our predicted values of y
yhat = linearfit.predict(X)
print(yhat)
residuals = yhat - y
----

=== 3.

[source,python]
----
plt.hist(residuals, bins=5)
----

image::./images/4-2.PNG[결과값]

=== 4.

[source,python]
----
import numpy as np

# sum the (predicted - observed) squared
SSE = np.sum((y.values-yhat)**2)
# Average y
ybar = np.mean(y.values)

# sum the (mean - predicted) squared
RSS = np.sum((ybar-yhat)**2)

# sum the (mean - observed) squared
TSS = np.sum((ybar-y.values)**2)
----

=== 6.

[source,python]
----
SSE = np.sum((y.values-yhat)**2)
ybar = np.mean(y.values)
RSS = np.sum((ybar-yhat)**2)
TSS = np.sum((y.values-ybar)**2)
R2 = RSS/TSS
print(R2)
----

=== 9.

[source,python]
----
# Print the models summary
print(linearfit.summary())

#The models parameters
print("\n",linearfit.params)
delta = linearfit.params["year"] * 15
----

=== 10.

[source,python]
----
# Enter your code here.
# Compute SSE
SSE = np.sum((y.values - yhat)**2)
# Compute variance in X
xvar = np.sum((pisa.year - pisa.year.mean())**2)
# Compute variance in b1
s2b1 = SSE / ((y.shape[0] - 2) * xvar)
----

=== 11.

[source,python]
----
from scipy.stats import t

# 100 values between -3 and 3
x = np.linspace(-3,3,100)

# Compute the pdf with 3 degrees of freedom
print(t.pdf(x=x, df=3))
# Pdf with 3 degrees of freedom
tdist3 = t.pdf(x=x, df=3)
# Pdf with 30 degrees of freedom
tdist30 = t.pdf(x=x, df=30)

# Plot pdfs
plt.plot(x, tdist3)
plt.plot(x, tdist30)
----

image::./images/4-9.PNG[결과값]

=== 12.

[source,python]
----
# The variable s2b1 is in memory.  The variance of beta_1
tstat = linearfit.params["year"] / np.sqrt(s2b1)
----

=== 13.

[source,python]
----
# At the 95% confidence interval for a two-sided t-test we must use a p-value of 0.975
pval = 0.975

# The degrees of freedom
df = pisa.shape[0] - 2

# The probability to test against
p = t.cdf(tstat, df=df)
beta1_test = p > pval
----
