= The Linear Regression Model
Learn how to use linear regression for machine learning.

== 1. Instance Based Learning Vs. Model Based Learning
* KNN은 예측시마다 이전사례 전체를 다시 학습하는 대표적인 instance based learning 이다.
  ** training process 에서는 실제 계산이 발생하지 않는다.
  ** 각 인스턴스의 testing 마다 모든 데이터에 대해 유클리드 거리 순 정렬과 상위 n 개의 데이터 선택으로 총 n^3의 복잡도를 갖는다.
* parametric machine learning 방법 (선형 회귀, 로지스틱 회귀)
  ** 훈련의 결과는 훈련 세트의 패턴을 가장 근사하게 만드는 수학적 함수(모델)이다.
  ** 피처와 대상 컬럼이 관계가 있을 것이라는 가정을 통해 작동한다.
  ** 학습 결과는 모델(수학 함수)로 예측시 함수에 값을 대입해 구할 수 있어 비용이 매우 저렴하다.

image::./images/m1_1_1.png[, 300]

* 이번 미션에서는 선형 회귀 모델을 사용하여 예측을 수행하는 방법에 대한 개요를 다룬다. (scikit-learn을 이용)
* 이번 코스의 후반부 미션에서는 모델이 데이터 세트에 어떻게 적용되는지, 피쳐들을 선택하고 변형하는 방법 등에 대해 알아볼 것입니다.

== 2. Introduction To The Data
* 이번 코스에서는 아이오와주 에임스의 주택판매 데이터셋을 이용한다.
* 데이터 세트의 각 행은 판매된 주택의 속성과 가격으로 구성된다.
* 이 코스에서는 여러 특성들을 통해 최종 판매 가격을 예측하는 모델을 작성하고 아래와 같은 질문에 대답한다.
  ** 판매가에 가장 영향을 많이 주는 속성은?
  ** 속성들을 이용해 판매 가격을 얼마나 효과적으로 예측할 수 있는지?

[source,python]
----
import pandas as pd

data = pd.read_csv("AmesHousing.txt", "\t")
train = data.iloc[:1460]
test = data.iloc[1460:]
print(data.info())

target = 'SalePrice'
----

== 3. Simple Linear Regression

image::./images/m1_3_1.png[, 150]

* 단순 선형 회귀의 목표는 피처 열과 대상 열 간의 관계를 가장 잘 설명하는 최적의 매개 변수 값(a1, a0)을 찾는 것

image::./images/m1_3_2.png[, 550]

[source,python]
----
import matplotlib.pyplot as plt
# For prettier plots.
import seaborn

plt.figure(1)
plt.scatter(x = data['Garage Area'], y = data['SalePrice'], c = 'orange')

plt.figure(2)
plt.scatter(x = data['Gr Liv Area'], y = data['SalePrice'], c = 'blue')

plt.figure(3)
plt.scatter(x = data['Overall Cond'], y = data['SalePrice'], c = 'red')
----

image::./images/m1_3_3.png[, 450]

== 4. Least Squares
* pandas 의 DataFrame.corr() 를 통해 피쳐별 상관계수를 확인할 수 있다.
  ** train[['Garage Area', 'Gr Liv Area', 'Overall Cond', 'SalePrice']].corr()

* Residual Sum of Squares (잔차의 제곱합)
  ** 선형회귀 모델의 최적 파라미터를 찾기 위해 잔차의 제곱합을 최적화할 필요가 있다.
  ** 잔차는 예측값과 실제값 차이의 차를 의미한다.

image::./images/m1_4_1.png[, 200]
image::./images/m1_4_2.png[, 200]
image::./images/m1_4_3.png[, 200]

== 5. Using Scikit-Learn To Train And Predict
* 사이킷런의 선형회귀 라이브러리를 이용해 계수와 절편을 구해본다.
[source,python]
----
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(train[['Gr Liv Area']], train[['SalePrice']])
a0 = lr.intercept_
a1 = lr.coef_[0]
print(a0)
print(a1)
----

== 6. Making Predictions
* 이전 스탭에서 구한 모델을 이용해 테스트셋을 예측해보고 RMSE를 구한다.
[source,python]
----
import numpy as np
from sklearn.metrics import mean_squared_error

lr = LinearRegression()
lr.fit(train[['Gr Liv Area']], train['SalePrice'])

train_prediction = lr.predict(train[['Gr Liv Area']])
train_mse = mean_squared_error(train[['SalePrice']], train_prediction)
train_rmse = np.sqrt(train_mse)

test_prediction = lr.predict(test[['Gr Liv Area']])
test_mse = mean_squared_error(test[['SalePrice']], test_prediction)
test_rmse = np.sqrt(test_mse)
----

== 7. Multiple Linear Regression
* 다중 선형 회귀를 통해 RMSE 의 개선을 살펴본다.
[source,python]
----
cols = ['Overall Cond', 'Gr Liv Area']

lr = LinearRegression()
lr.fit(train[cols], train['SalePrice'])

train_prediction = lr.predict(train[cols])
train_mse = mean_squared_error(train_prediction, train['SalePrice'])
train_rmse_2 = np.sqrt(train_mse)

test_prediction = lr.predict(test[cols])
test_mse = mean_squared_error(test_prediction, test['SalePrice'])
test_rmse_2 = np.sqrt(test_mse)
----
