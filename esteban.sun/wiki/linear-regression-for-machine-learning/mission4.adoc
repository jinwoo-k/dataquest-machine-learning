== Ordinary Least Squares
 * Cost Function
   ** 그라디언트 디센트와 달리 OLS 예측은 최적 매개 변수 값을 찾는 문제에 대한 수학적 솔루션을 제공
   ** 반면, Gradient descent는 초기 매개 변수 값, 학습 속도 등을 기준으로 다른 수의 반복 (따라서 수학 연산의 수를 달라야 함)을 요구할 수있는 알고리즘 방식.
   ** 비용 함수가 행렬 형식으로 표현되는 방법에 대해 알아보기 전에 오류가 어떻게 표현되는지 이해가 필요
   ** 오류는 모델 y^(예측벡터) 와 실제 레이블 y를 사용하여 만들어진 예측의 차이이기 때문에 벡터로 표시됨
   ** ε 은 오차 벡터를 나타 내기 위해 사용됨

 * Gradient Descent vs. Ordinary Least Squares
   ** OLS의 한계.
      *** 데이터가 클 때 OLS 추정이 계산 비용이 많이 든다는 것
      *** OLS는 일반적으로 데이터 집합의 요소 수 (따라서 반전 된 행렬)가 수백만 개 요소 미만인 경우에 주로 사용
   ** Gradient Descent
      *** 큰 데이터 세트에서는 그라디언트 디센트가 훨씬 더 융통성이 있기 때문에 사용됩니다.
      *** 실용적인 많은 문제에 대해 우리는 임계 값 정확도 값 (또는 설정된 반복 횟수)을 설정하고 "충분히 좋은" 해결책을 사용할 수 있다

== 활용 주요 function
 * import pandas as pd
 * import numpy as np
 * function
   ** np.linalg.inv(np.dot(np.transpose(X), X))
      ** inv : 역함수, transpose : 전치행렬
