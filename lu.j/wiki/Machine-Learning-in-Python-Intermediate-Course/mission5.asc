= Overfitting

== 1. Introdution
* 이 임무에서는 Overfitting을 식별하는 방법과 이를 피해기 위해 할 수 있는 일을 모색할 것
* 오버 피팅을 탐색하기 위해 자동차의 연료 효율성에 영향을 줄 수 있는 7가지 수치 기능이 포함된 데이터 셋을 사용한다.
** cylinders - 엔진의 실린더 개수
** displacememt - 엔진의 배수량
** horsepower - 마력
** weight - 차의 중량
** acceleration - 차의 가속도
** modal year - 모델의 출시일
** origin - 제조국
* mpg 열은 우리의 목표열이고 다른 기능을 이용해 예측하고자 하는 열

== 2. Bias and Variance
* Overfitting 핵심은 bias와 variancc를 이해하는 것이다.
* 바이어스와 분산은 우리가 간접적으로 제어할 수 있는 모델에서 관찰 가능한 2가지 오류 원인이다.
* 바이어스는 학습 알고리즘에 대한 잘못된 가정을 초래하는 오류를 설명한다.
* 분산은 모델의 예측된 값의 다양성 때문에 발생하는 오류를 설명한다.
* 가장 이상적인 것은 낮은 바이어스와 낮은 분산이다.

== 3. Bias-variance tradeoff
* 2개의 모델 사이에서 하나는 다른 하나보다 더 오버피팅 될 것이다.
* 바이어스 분산을 이해하는 것은 오버피팅 이해에 중요하다.
* 오버피팅 모델은 데이터셋의 잡음을 포착하는 경향이 있다.

image::./images/tradeoff.PNG[tradeoff]

== 4. Multivariate models

== 5. Cross validation
* 모델이 오버피팅인지 여부를 감지하는 좋은 방법은 샘플 내 오류와 샘플 외부 오류를 테스트 오류와 비교하는 것
* 여기서는 교차 유효성 검사를 사용하여 계산한다.
* 모델의 교차 유효성 검사 오류가 샘플 오류보다 훨씬 높으면 훈련된 모델이 교육 셋 외부에서 일반화되지 않는다는 지표이다.

== 6. Plotting cross-validation error vs. cross-validation variance
* 평균 제곱 오류값이 낮아짐에 따라 예측의 분산이 커졌다.
* 낮은 제곱 오류값을 가진 모델은 입력값의 작은 변화에 보다 민감한 모델 복잡성을 가지므로 예상할 수 있다.

== 7. Conclusion
* 고차원 다변량 모델은 하위 다 변수 모델과 관련하여 오버피팅 되지만 샘플내 오차 및 샘플 이탈은 많은 차이를 보이지 않았다.
* 모델의 복잡성이 증가함에 따라 전체 분산은 25% 증가했다.

== 예제

=== 1.

[source,python]
----
import pandas as pd
columns = ["mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model year", "origin", "car name"]
cars = pd.read_table("auto-mpg.data", delim_whitespace=True, names=columns)
filtered_cars = cars[cars['horsepower'] != '?']
filtered_cars['horsepower'] = filtered_cars['horsepower'].astype('float')
----

=== 3.

[source,python]
----
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

def train_and_test(cols):
    features = filtered_cars[cols]
    target = filtered_cars["mpg"]

    lr = LinearRegression()
    lr.fit(features, target)

    predictions = lr.predict(features)

    mse = mean_squared_error(filtered_cars["mpg"], predictions)
    variance = np.var(predictions)
    return (mse, variance)

cyl_mse, cyl_var = train_and_test(["cylinders"])
weight_mse, weight_var = train_and_test(["weight"])
----


=== 4.

[source,python]
----
# Our implementation for train_and_test, takes in a list of strings.
def train_and_test(cols):
    # Split into features & target.
    features = filtered_cars[cols]
    target = filtered_cars["mpg"]
    # Fit model.
    lr = LinearRegression()
    lr.fit(features, target)
    # Make predictions on training set.
    predictions = lr.predict(features)
    # Compute MSE and Variance.
    mse = mean_squared_error(filtered_cars["mpg"], predictions)
    variance = np.var(predictions)
    return(mse, variance)

one_mse, one_var = train_and_test(["cylinders"])
two_mse, two_var = train_and_test(["cylinders", "displacement"])
three_mse, three_var = train_and_test(["cylinders", "displacement", "horsepower"])
four_mse, four_var = train_and_test(["cylinders", "displacement", "horsepower", "weight"])
five_mse, five_var = train_and_test(["cylinders", "displacement", "horsepower", "weight", "acceleration"])
six_mse, six_var = train_and_test(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year"])
seven_mse, seven_var = train_and_test(["cylinders", "displacement", "horsepower", "weight", "acceleration","model year", "origin"])
----


=== 5.

[source,python]
----
from sklearn.cross_validation import KFold
from sklearn.metrics import mean_squared_error
import numpy as np

def train_and_cross_val(cols):
    features = filtered_cars[cols]
    target = filtered_cars['mpg']

    variance_values = []
    mse_values = []

    kf = KFold(n=len(filtered_cars), n_folds=10, shuffle=True, random_state=3)

    for train_index, test_index in kf:
        x_train, x_test = features.iloc[train_index], features.iloc[test_index]
        y_train, y_test = target.iloc[train_index], target.iloc[test_index]

        lr = LinearRegression()
        lr.fit(x_train, y_train)
        predictions = lr.predict(x_test)

        mse = mean_squared_error(y_test, predictions)
        var = np.var(predictions)

        variance_values.append(var)
        mse_values.append(mse)

    avg_mse = np.mean(mse_values)
    avg_var = np.mean(variance_values)
    return (avg_mse, avg_var)


two_mse, two_var = train_and_cross_val(["cylinders", "displacement"])
three_mse, three_var = train_and_cross_val(["cylinders", "displacement", "horsepower"])
four_mse, four_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight"])
five_mse, five_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration"])
six_mse, six_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year"])
seven_mse, seven_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration","model year", "origin"])
----


=== 5.

[source,pyhton]
----
import matplotlib.pyplot as plt

two_mse, two_var = train_and_cross_val(["cylinders", "displacement"])
three_mse, three_var = train_and_cross_val(["cylinders", "displacement", "horsepower"])
four_mse, four_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight"])
five_mse, five_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration"])
six_mse, six_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year"])
seven_mse, seven_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration","model year", "origin"])
plt.scatter([2,3,4,5,6,7], [two_mse, three_mse, four_mse, five_mse, six_mse, seven_mse], c='red')
plt.scatter([2,3,4,5,6,7], [two_var, three_var, four_var, five_var, six_var, seven_var], c='blue')
plt.show()
----

image::./images/5-1.PNG[결과값]
