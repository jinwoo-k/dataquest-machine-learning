= Evaluating Model Performance

== 1. 예측 품질 평가
* 모델의 품질을 테스트 하는 간단한 방법 (트레이닝/테스트 검증)
** 데이터 셋을 두개의 파티션으로 분할
*** 트레이닝 셋 : 대부분의 데이터 (75%)
*** 테스트 셋 : 트레이닝 셋을 제외한 데이터 (25%)
** 트레이닝 셋을 가지고 테스트 셋의 가격을 예측하라
*** 테스트 셋에 예측가격 이라는 필드 생성
** 예측가격과 실제 가격 필드를 비교하여 정확성 판별

NOTE: 기계학습이 수행될때마다 유효성 검증을 통해 더 좋은 예측을 할수 있도록 하기 위한 작업

* dc_listings 3723 -> traning_set : 2792, test_set : 931

[source,python]
----
import pandas as pd
import numpy as np
dc_listings = pd.read_csv("dc_airbnb.csv")
stripped_commas = dc_listings['price'].str.replace(',', '')
stripped_dollars = stripped_commas.str.replace('$', '')
dc_listings['price'] = stripped_dollars.astype('float')
train_df = dc_listings.iloc[0:2792]
test_df = dc_listings.iloc[2792:]

def predict_price(new_listing):
    temp_df = train_df
    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))
    temp_df = temp_df.sort_values('distance')
    nearest_neighbor_prices = temp_df.iloc[0:5]['price']
    predicted_price = nearest_neighbor_prices.mean()
    return(predicted_price)

test_df['predicted_price'] = test_df['accommodates'].apply(lambda x: predict_price(x))
----

== 2. 오류 측정
* 오류 측정 기준은 예측치가 실제 값과 얼마나 부정확한지를 수치화함
* mean error - 예측값과 실제값 차이를 계산 한 뒤 차이의 평균값을 계산
** 평균 오차 값은 양수와 음수로 나뉘는데 서로 상쇄됨
* mean absolute error - 평균 절대 오류 (차이의 절대값의 평균값 계산)

* mae 측정

[source,python]
----
import numpy as np
test_df['squared_error'] = np.absolute(test_df['predicted_price'] - test_df['price'])
mae = test_df['squared_error'].mean()
print(mae)
----

== 3. Mean Squared Error(MSE)
* 예상값과 실제값 차이를 명확히 나타냄

== 4. 다른 모델 연습
[source,python]
----
train_df = dc_listings.iloc[0:2792]
test_df = dc_listings.iloc[2792:]

def predict_price(new_listing):
    temp_df = train_df
    temp_df['distance'] = temp_df['bathrooms'].apply(lambda x: np.abs(x - new_listing))
    temp_df = temp_df.sort_values('distance')
    nearest_neighbors_prices = temp_df.iloc[0:5]['price']
    predicted_price = nearest_neighbors_prices.mean()
    return(predicted_price)

test_df['predicted_price'] = test_df['bathrooms'].apply(lambda x: predict_price(x))
test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)
mse = test_df['squared_error'].mean()
print(mse)
----

== 5. Root Mean Squared Error(RMSE)
* MSE는 제곱되어 있어서 대상과 다른 단위를 이용하기 때문에 상대적 차이만 알수 있음
* MSE의 제곱근이 RMSE
* RMSE는 대상과 동일한 단위를 이용함

[source,python]
----
def predict_price(new_listing):
    temp_df = train_df
    temp_df['distance'] = temp_df['bathrooms'].apply(lambda x: np.abs(x - new_listing))
    temp_df = temp_df.sort_values('distance')
    nearest_neighbors_prices = temp_df.iloc[0:5]['price']
    predicted_price = nearest_neighbors_prices.mean()
    return(predicted_price)

test_df['predicted_price'] = test_df['bathrooms'].apply(lambda x: predict_price(x))
test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)
mse = test_df['squared_error'].mean()
rmse = mse ** (1/2)
print(rmse)
----

== 6. MAE 와 RMSE 비교
* MAE - 각 오차값(실제값과 예측값의 차이)이 선형적으로 증가함
* RMSE - 각 오차값에 제곱을 한 뒤 제곱근을 적용함, 이는 각 오차값이 클수록 RMSE 값에 영향을 준다는 것을 의미함
* 아래 예제로 두가지의 비교를 할 수 있음

[source,python]
----
errors_one = pd.Series([5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10])
errors_two = pd.Series([5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 1000])
mae_one = errors_one.sum()/len(errors_one)
rmse_one = np.sqrt((errors_one**2).sum()/len(errors_one))
print(mae_one)
print(rmse_one)

mae_two = errors_two.sum()/len(errors_two)
rmse_two = np.sqrt((errors_two**2).sum()/len(errors_two))
print(mae_two)
print(rmse_two)
----

Result_1::
  * mae_one: 7.5 
  * rmse_one: 7.90569415042
Result_2::
  * mae_two: 62.5
  * rmse_two: 235.823026865

== 7. Next Steps
* 일반적으로 RMSE의 값은 MAE 값보다 작을 것을 예상해야한다.
* MAE : RMSE의 비율로 오류가 있는지 여부를 알 수 있다. 

* Which Metric is Better? - https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d[Which Metric is Better?]
** 이 컬럼의 내용은 alfred가 요약을 잘 해주셨어요. 
