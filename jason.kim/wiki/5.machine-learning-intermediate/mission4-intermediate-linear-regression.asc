= Intermediate Linear Regression
Learn how to use linear regression to estimate the speed at which the Leaning Tower of Pisa was moving.

== 1. Introduction to the Data
* 피사의 사탑은 수백년동안 서서히 한쪽으로 기울었다. (1988년부터 복원중이다.)
* 1975년부터 7987년까지의 기울기 데이터를 이용해 기울기를 예측한다.

[source,python]
----
import pandas
import matplotlib.pyplot as plt

pisa = pandas.DataFrame({"year": range(1975, 1988),
                         "lean": [2.9642, 2.9644, 2.9656, 2.9667, 2.9673, 2.9688, 2.9696,
                                  2.9698, 2.9713, 2.9717, 2.9725, 2.9742, 2.9757]})

plt.scatter(pisa['year'], pisa['lean'])
----

image:./images/m4_1_1.png[, 500]

== 2. Fit the Linear Model
* 방금 scatter plot 을 봤을때 선형 회귀가 데이터에 적합하다 판단된다.
* 본 미션에서는 선형 회귀 모델의 중요 통계 개념에 대해 배운다.
* Statsmodels : 파이썬의 정교한 통계분석 라이브러리
* sm.OLS class 는 Ordinary Least Square 방식으로 선형 모델에 핏 시키고 결과로 계수를 반환한다.
  ** 절편을 얻기 위해 상수 컬럼을 한개 추가한다.

[source,python]
----
import statsmodels.api as sm

y = pisa.lean # target
X = pisa.year  # features
X = sm.add_constant(X)  # add a column of 1's as the constant term

# OLS -- Ordinary Least Squares Fit
linear = sm.OLS(y, X)
# fit model
linearfit = linear.fit()

print(linearfit.summary())
print(pisa)
----


== 3. Define a Basic Linear Model
* 선형회귀 모델 공식 : image:./images/m4_3_1.png[, 200]
  ** image:./images/m4_3_3.png[, 120] 잔차는 예측값과 관측값 사이의 차이이다.
  ** image:./images/m4_3_2.png[, 130] ei 는 잔차로 평균 0, 분산 σ^2 을 갖는 정규분포 값이다.
    *** 모델이 예측값과 관측 값 사이의 오차를 정규 분포하고 평균 오차를 0으로 가정함을 의미
  ** β0는 절편이고 β1은 기울기이다.
  ** image:./images/m4_3_4.png[, 150] : 예측치의 표현

[source,python]
----
# Our predicted values of y
yhat = linearfit.predict(X)
print(yhat)

residuals = yhat - y
print(residuals)
----

== 4. Histogram of Residuals
* 잔차가 정규성을 갖는지 확인하기위해 히스토그램 이용

[source,python]
----
plt.hist(residuals, bins = 5)
----

== 5. Interpretation of Histogram
* 관측치가 너무 적어(13건) 이 잔차가 정상이라고 판단하기 힘듬
* 앞으로 통계적 적합성 측정방법을 살펴봄

== 6. Sum of Squares
* 선형 회귀 모델을 평가하는 데 사용되는 많은 통계적 측정 방법은 3 개의 제곱합 측정 값에 의존
* SSE (Sum of Square Error)
  ** image:./images/m4_6_1.png[, 300]
  ** 잔차의 합

* RSS (Regression Sum of Squares)
  ** image:./images/m4_6_2.png[, 350]
  ** 관측치와 예측치 사이의 분산
  ** RSS 가 높다면 평균으로 예측했다는 의미이므로 쓸모없는 모델이다.

* TSS (Total Sum of Squares)
  ** image:./images/m4_6_3.png[, 200]
  ** 데이터의 분산

* 큰 RSS와 작은 SSE는 강력한 모델의 지표가 될 수 있습니다.
* TSS = RSS + SSE

[source,python]
----
import numpy as np

# sum the (observed - predicted) squared
SSE = np.sum((y.values-yhat)**2)

avg = np.sum(y.values) / len(y)
RSS = np.sum((avg - yhat) ** 2)
TSS = np.sum((y.values - avg) ** 2)
----

== 7. R-Squared
* 결정 계수 (R-Squared)는 선형 의존성의 훌륭한 척도로 타겟 변수의 변동 비율이 우리 모델에 의해 얼마나 잘 설명되는지를 말함
* image:./images/m4_7_1.png[, 200]
* 0과 1 사이의 값을 가지며, 1에 가까울 수록 좋은 결과이다.

[source,python]
----
SSE = np.sum((y.values-yhat)**2)
ybar = np.mean(y.values)
RSS = np.sum((ybar-yhat)**2)
TSS = np.sum((y.values-ybar)**2)

R2 = RSS / TSS
----

== 8. Interpretation of R-Squared
* 위의 예제 결과 R^2 는 0.988 로 데이터의 98.8% 변량이 설명된다.

== 9. Coefficients of the Linear Model
* 계수를 통해 모델을 설명할 수 있는 부분이 선형회귀 모델의 장점이다.
* 그 계수의 신뢰도를 측정할 수 있느 방법이 있다.
* sm.OLS 의 피팅 결과 중 요약정보에는 r-squared, 관측 수 등 많은 정보가 있다.
* 이전 예제에서 계수는 일년동안 기울어지는 미터를 나타낸다.

[source,python]
----
# Print the models summary
print(linearfit.summary())

#The models parameters
print("\n",linearfit.params)

delta = 15 * linearfit.params['year']

print(delta)
----

== 10. Variance of Coefficients
* 표준 오차는 추정 된 분산의 제곱근
* 단일 변수 선형 모델에 대한 추정 분산 : image:./images/m4_10_1.png[, 500]
  ** SSE는 모델내의 오류를 표현
  ** 분모항 image:./images/m4_10_2.png[, 150] 은 독립변수 x의 분산값
  ** (n-2) 로 나눈는 이유는 모델에서 SSE텀을 자유도 2도로 정규화 하기 위함
  ** 이 분산을 사용하여이 β1에 관한 t-statistics 및 신뢰 구간을 계산할 수 있음
[source,python]
----
x_mean = np.sum(pisa.year) / len(pisa)
x_var = np.sum((pisa.year - x_mean) ** 2)

s2b1 = SSE / ((len(pisa) - 2) * x_var)
----

11. T-Distribution
* 타워의 경사가 연도와 관계있다는 점을 통계 테스트를 통해 알 수 있다.
* Student t-test : 통계적 유의성에 대한 일반적인 테스트
  ** student t-test 는 t 분포에 의존하는데, 정규분포와 비슷하지만 피크가 더 낮다.
  ** 같은 모집단에서 추출된 표본의 분산이 같으면 그 평균도 같다는 가설을 검정할 때 자주 응용
  ** 실제 모평균이 있을 구간, 즉 평균의 신뢰구간을 설정하기 위해 사용되며 확률도를 명확히 나타낼 수 있음.

* t-분포는 표본 집합의 관측 횟수를 고려하며, 이 표본은의 전체집합은 정규분포라고 가정한다.
* 일반적으로, 표본이 작을수록 우리가 추정치에 있는 신뢰도가 떨어진다.
* T분포는 이를 고려해 관찰 횟수에 비례하여 분산을 증가시킨다.
* 관찰 횟수가 증가함에 따라 t분포가 정규 분포에 접근한다.

* 유의성 검정에 t-분포의 밀도 함수 사용
  ** 확률 밀도 함수 (pdf) : 연속 확률 변수의 상대 우도를 모델링
  ** 누적 밀도 함수 (cdf) : 확률 변수가 한 점보다 작거나 같을 확률을 모델링
  ** 자유도 (df) : 표본의 관측 수
    *** 일반적으로 자유도는 관찰 수에서 2를 뺀 값과 같다.

[source,python]
----
from scipy.stats import t

# 100 values between -3 and 3
x = np.linspace(-3,3,100)

# Compute the pdf with 3 degrees of freedom
print(t.pdf(x=x, df=3))

tdist3 = t.pdf(x=x, df=3)
tdist30 = t.pdf(x=x, df=30)
plt.plot(tdist3, tdist30)
----

== 12. Statistical Significance of Coefficients
* 계수의 통계적 유의성에 대해 살펴본다.
* 귀무가설은 피사의 사탑의 기울어짐이 연도와 관계가 없다는 것이며, 그 계수가 0임을 의미한다.
* 대립가설은 탑의 기울기가 연도와 관계가 있다는 것이며, 그 계수가 0이 아님을 의미한다.
* image:./images/m4_12_1.png[, 200]
* 귀무 가설을 테스트하는 것은 t분포를 사용 t-통계량은 다음과 같이 정의
  ** image:./images/m4_12_2.png[, 120]
  ** 이 통계량은 기대 계수가 0에서부터 얼마나 많은 표준 편차를 갖는지 측정
  ** β1이 0 일 때 분산이 낮으면 t는 매우 높아짐
  ** pdf에서 볼 수 있듯이 0에서 멀리 떨어진 t-통계량은 매우 낮은 확률을 갖음

== 13. The P-Value
* t-통계량을 이용한 계수 테스트
* 95% 유의 수준에서 β1이 0이 아닌 확률
  ** β1이 0과 95% 차이가 나는 것
  ** 95% 신뢰 구간에서 β1이 양수인지 음수인지를 테스트하기 위해 분포에서 2.5와 97.5 백분위 수를 관찰, 두 값 사이에 95% 신뢰를 남긴다.
  ** t분포가 0에 대해 대칭이므로 절대 값을 취하여 97.5 백분위 수(양수 측)에서만 테스트할 수 있게 함
  ** 확률이 0.975보다 크다면 우리는 귀무 가설 (H0)을 기각하고 그 해가 타워의 기울기에 유의미한 영향을 미친다고 말할 수 있다.

[source,python]
----
# At the 95% confidence interval for a two-sided t-test we must use a p-value of 0.975
pval = 0.975

# The degrees of freedom
df = pisa.shape[0] - 2

# The probability to test against
p = t.cdf(tstat, df=df)
beta1_test = p > pval
----
