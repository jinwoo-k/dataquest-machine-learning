= K-Means Clustering

== 1. clustering NBA Players
* NBA 2013~2014 시즌의 플레이어 실적 데이터 셋으로 수행한다.

[source,python]
----
import pandas as pd
import numpy as np

nba = pd.read_csv("nba_2013.csv")
nba.head(3)
----

== 2. Point Guards
* 포인트 가드는 팀의 득점 기회를 창출해야 하기 때문에 팀의 가장 중요한 역할 중 하나이다.
* 포인트 가드의 유형을 시각화 하고 유사한 포인트 가드를 그룹화 할 수 있다.
* 2개의 기능을 사용
** 턴오버 레이팅 - 플레이어가 생성한 점수 부여 기회의 수를 정량화
** 게임별 점수

[source,python]
----
point_guards = nba[nba['pos'] == 'PG']
----

== 3. Points Per Game
* 데이터 셋에는 게임 당 포인트 값이 없지만 각 플레이어의 총 포인트(PTS)와 플레이 한 게임 수(g)를 사용하여 계산할 수 있다.

[source,python]
----
point_guards['ppg'] = point_guards['pts'] / point_guards['g']

# Sanity check, make sure ppg = pts/g
point_guards[['pts', 'g', 'ppg']].head(5)
----

== 4. Assist Turnover Ratio
* 총 어시스트 수(ast)를 총 턴오버(ts)로 나눈 atr을 계산해본다.

image::./images/7-1.PNG[ATR]

[source,python]
----
point_guards = point_guards[point_guards['tov'] != 0]
point_guards['atr'] = point_guards['ast'] / point_guards['tov']
----

== 5. Visualizing the point guards
* X축의 게임당 점수(ppg), Y축을 턴오버 레이팅으로 한 산점도를 표출

[source,python]
----
plt.scatter(point_guards['ppg'], point_guards['atr'], c='y')
plt.title("Point Guards")
plt.xlabel('Points Per Game', fontsize=13)
plt.ylabel('Assist Turnover Ratio', fontsize=13)
plt.show()
----

image::./images/7-2.PNG[Plot]

== 6. Clustering player
* 데이터 클러스터링에는 여러 방법이 있는데 그 중 중심기반 클러스터링에 초점을 맞출 것이다.
* 중심기반 클러스터링 - 클러스터가 센터가 있는 원과 유사할 때 잘 작동한다.
** 중심 - 해당 클러스터에 있는 모든 데이터 포인트의 산술 평균을 의미
** K-Means Clustering - 중심 기반 클러스터링의 한 종류
*** K는 데이터를 분류할 클러스터의 수를 의미
*** K-Means의 핵심은 K가 무엇인지를 지정해야함 (여기서는 데이터를 5개로 나눌것이므로 K=5)

== 7. The Algorithm
* K-Means 설정은 각 클러스터의 중심과 해당 클러스터에 속한 플레이어의 재계산 사이를 전환하는 반복 알고리즘이다.
* 1단계(클러스터에 포인트 지정) - 각 플레이어에 대해 해당 플레이어의 좌표 또는 atr & ppg 값과 각 중심 좌표간의 유클리드 거리를 계산한다.
** 중심값이 플레이어의 값과 가장 가깝거나 유클리드 거리가 가장 낮은 클러스터에 플레이어를 할당
* 2단계(클러스터의 새로운 중심 업데이트) - 각 클러스터에 대해 해당 클러스터의 모든 포인트(플레이어)의 산술 평균을 계산해 새 중심을 계산
** 산술평균 - 모든 X값(atr)의 평균과 모든 Y값(ppg)의 평균으로 계산
* 클러스터가 더이상 움직이지 않을때까지 1,2를 반복

[source,python]
----
num_clusters = 5
# Use numpy's random function to generate a list, length: num_clusters, of indices
random_initial_points = np.random.choice(point_guards.index, size=num_clusters)
# Use the random indices to create the centroids
centroids = point_guards.loc[random_initial_points]
----

== 8. Visualize Centroids

[source,python]
----
plt.scatter(point_guards['ppg'], point_guards['atr'], c='yellow')
plt.scatter(centroids['ppg'], centroids['atr'], c='red')
plt.title("Centroids")
plt.xlabel('Points Per Game', fontsize=13)
plt.ylabel('Assist Turnover Ratio', fontsize=13)
plt.show()
----

image::./images/7-3.PNG[Plot]

== 9. Setup(continued)
* 반복할때 중심값은 다른 플레이어의 좌표와 일치하지 않는 좌표였다.
* 이제부터는 중심값보다는 dictionary 오브젝트를 사용하도록 한다.
* 각 클러스터의 중심과 중심좌표의 목록 표현을 하기 위해 키값이 필요 (cluster_id)
* cluster_ids를 생성하려면 각 중심을 반복하고 0~(k-1)까지 정수를 할당

[source,python]
----
def centroids_to_dict(centroids):
    dictionary = dict()
    # iterating counter we use to generate a cluster_id
    counter = 0

    # iterate a pandas data frame row-wise using .iterrows()
    for index, row in centroids.iterrows():
        coordinates = [row['ppg'], row['atr']]
        dictionary[counter] = coordinates
        counter += 1

    return dictionary

centroids_dict = centroids_to_dict(centroids)
----

== 10. Step 1 (Euclidean Distance)
* 플레이어를 클러스터에 할당하기 전에 플레이어의 ppg 및 atr 값을 각 클러스터의 중심과 비교하는 방법이 필요
** 유클리드 거리를 이용해 계산

image::./images/7-4.PNG[계산식]

[source,python]
----
import math

def calculate_distance(centroid, player_values):
    root_distance = 0

    for x in range(0, len(centroid)):
        difference = centroid[x] - player_values[x]
        squared_difference = difference**2
        root_distance += squared_difference

    euclid_distance = math.sqrt(root_distance)
    return euclid_distance

q = [5, 2]
p = [3,1]

# Sqrt(5) = ~2.24
print(calculate_distance(q, p))
----

== 11. Step 1(continued)
* 이제 유클리드 거리 기반으로 클러스터에 데이터 포인트를 할당하는 방법이 필요
** point_guard 데이터 프레임에 속한 클러스터의 cluster_id가 포함된 열을 추가

[source,python]
----
def assign_to_cluster(row):
    lowest_distance = -1
    closest_cluster = -1

    for cluster_id, centroid in centroids_dict.items():
        df_row = [row['ppg'], row['atr']]
        euclidean_distance = calculate_distance(centroid, df_row)

        if lowest_distance == -1:
            lowest_distance = euclidean_distance
            closest_cluster = cluster_id
        elif euclidean_distance < lowest_distance:
            lowest_distance = euclidean_distance
            closest_cluster = cluster_id
    return closest_cluster

point_guards['cluster'] = point_guards.apply(lambda row: assign_to_cluster(row), axis=1)
----

== 12. Visualizing Clusters

[source,python]
----
def visualize_clusters(df, num_clusters):
    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']

    for n in range(num_clusters):
        clustered_df = df[df['cluster'] == n]
        plt.scatter(clustered_df['ppg'], clustered_df['atr'], c=colors[n-1])
        plt.xlabel('Points Per Game', fontsize=13)
        plt.ylabel('Assist Turnover Ratio', fontsize=13)
    plt.show()

visualize_clusters(point_guards, 5)
----

image::./images/7-5.PNG[plot]

== 13. Step 2
* 클러스터의 중심을 다시 계산해본다.

[source,python]
----
def recalculate_centroids(df):
    new_centroids_dict = dict()

    for cluster_id in range(0, num_clusters):
        values_in_cluster = df[df['cluster'] == cluster_id]
        # Calculate new centroid using mean of values in the cluster
        new_centroid = [np.average(values_in_cluster['ppg']), np.average(values_in_cluster['atr'])]
        new_centroids_dict[cluster_id] = new_centroid
    return new_centroids_dict

centroids_dict = recalculate_centroids(point_guards)
----

== 14. Repeat Step1
* 1단계를 다시 실행하고 결과값을 비교해보자.

[source,python]
----
point_guards['cluster'] = point_guards.apply(lambda row: assign_to_cluster(row), axis=1)
visualize_clusters(point_guards, num_clusters)
----

image::./images/7-6.PNG[plot]

== 15. Repeat Step 2 and Step 1

[source,python]
----
centroids_dict = recalculate_centroids(point_guards)
point_guards['cluster'] = point_guards.apply(lambda row: assign_to_cluster(row), axis=1)
visualize_clusters(point_guards, num_clusters)
----

== 16. Challengers of K-Means
* 1단계와 2단계를 반복하고 visualize_clusters를 실행하면 모든 반복(2개의 클러스터가 거의 겹치는 영역)에서 클러스터를 변경하는 몇가지 포인트가 있는걸 발견할 수 있다.
** K-Means는 클러스터 구성에 엄청난 변화를 일으키지 않는다.
** K-Means는 반복하는데 있어서 보수적이기 때문에 초기 중심점을 선택하는 위치와 플레이어를 클러스터에 할당하는게 중요하다.

[source,python]
----
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=num_clusters)
kmeans.fit(point_guards[['ppg', 'atr']])
point_guards['cluster'] = kmeans.labels_

visualize_clusters(point_guards, num_clusters)
----

== 17. Conclusion
* 다음장에서는 중심값을 이용하지 않고 데이터를 클러스터링 하는 방법 및 더 많은 기능을 사용해 클러스터하는 방법을 살펴볼 예정이다.
