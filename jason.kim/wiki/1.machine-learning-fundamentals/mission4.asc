= Hyperparameter Optimization

Vary the k value to improve performance.

== 1. Recap
* 이전 미션에서는 예측에 사용되는 속성을 늘리는데 초점을 맞췄다.
* 그리고 그 속성은 유사도 랭킹과 연관 있는 속성을 선택했을때 오차가 줄어듬을 확인했다.
* 이번 미션에서는 예측을 위한 인접 이웃 수인 k값을 증가시키는데 초점을 맞춘다.

== 2. Hyperparameter Optimization
* k값 변경은 피쳐 변경과 달리 데이터에 영향 없이 모델의 동작에 영향을 준다.
* 사용되는 데이터와 관계 없이 모델의 동작 및 성능에 영향을 주는 값을 하이퍼 파라미터라 한다.
* 최적의 하이퍼 파라미터를 찾는 과정을 hyperparameter optimization 이라 부르며, 간단하지만 일반적 기법으로 grid search 가 있다.
1. 하이퍼 파라미터의 서브셋을 선택한다.
2. 선택된 하이퍼 파라미터를 이용해 모델을 트레이닝 한다.
3. 모델의 성능을 측정한다.
4. 위의 과정을 반복해 가장 오류가 낮은 하이퍼 파라미터 셋을 선택한다.
* KNN에서 하이퍼 파라미터 최적화는 가장 낮은 오류를 발생시키는 k값을 찾는 것이다. (데이터 셋이 큰 경우 오래걸림)

== 3. Expanding Grid Search
* k값을 1부터 20까지 증가시켜보며 mse 가 최소가 되는 k값을 찾는다.
* 만약 더 낮은 mse가 나올 것 같다면 k값을 더욱 증가시켜봐도 된다.

== 3. Visualizing Hyperparameter Values
* k 값에 따른 mse 의 변화를 산점도를 이용해 그래프로 본다.

== 5. Varying Features And Hyperparameters
* 이전 미션에서 수행했던 성능이 안좋은 모델에 대해서 k값 변화시 mse 를 낮출 수 있는지 확인한다.

== 6. Practice The Workflow
* 가장 좋은 모델을 찾는 일반적인 워크플로우는 다음과 같다.
1. 목표 컬럼을 예측하기 위해 사용할 연관된 피쳐를 선택한다.
2. 그리드 서치를 이용해 해당 피쳐들에 최적화된 하이퍼 파라미터를 찾는다.
3. 모델의 정확도를 평가하고 위의 과정을 반복한다.
* 앞의 미션에서 ['accommodates', 'bathrooms'], ['accommodates', 'bathrooms', 'bedrooms'] 를 이용해서 수행했던 KNN을 최적의 K값에 대한 mse를 구해본다.

== 7. Next Steps
* 적절한 피쳐 선택과 함께 최적의 k값을 찾는것이 중요하다는 것을 배웠다.
* 다음 단계에서는 새로운 데이터셋을 이용해 우리가 배운것을 실습할 것 이다.
